{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f418aa-fc77-42f2-9aa5-c2697c352727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import zstandard\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import logging.handlers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b09a1f2-c7c1-4687-bdd8-baf422cbb210",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the path to the input file, or a folder of files to process all of\n",
    "input_folder = r\"/Volumes/Untitled/reddit/subreddits23\"\n",
    "# put the name or path to the output file. The file extension from below will be added automatically. If the input file is a folder, the output will be treated as a folder as well\n",
    "output_folder = r\"/Volumes/Untitled/reddit/subreddits23_csv\"\n",
    "# the format to output in, pick from the following options\n",
    "#   zst: same as the input, a zstandard compressed ndjson file. Can be read by the other scripts in the repo\n",
    "#   txt: an ndjson file, which is a text file with a separate json object on each line. Can be opened by any text editor\n",
    "#   csv: a comma separated value file. Can be opened by a text editor or excel\n",
    "# WARNING READ THIS: if you use txt or csv output on a large input file without filtering out most of the rows, the resulting file will be extremely large. Usually about 7 times as large as the compressed input file\n",
    "output_format = \"csv\"\n",
    "# override the above format and output only this field into a text file, one per line. Useful if you want to make a list of authors or ids. See the examples below\n",
    "# any field that's in the dump is supported, but useful ones are\n",
    "#   author: the username of the author\n",
    "#   id: the id of the submission or comment\n",
    "#   link_id: only for comments, the fullname of the submission the comment is associated with\n",
    "#   parent_id: only for comments, the fullname of the parent of the comment. Either another comment or the submission if it's top level\n",
    "single_field = None\n",
    "# the fields in the file are different depending on whether it has comments or submissions. If we're writing a csv, we need to know which fields to write.\n",
    "# set this to true to write out to the log every time there's a bad line, set to false if you're expecting only some of the lines to match the key\n",
    "write_bad_lines = True\n",
    "\n",
    "# only output items between these two dates\n",
    "from_date = datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
    "to_date = datetime.strptime(\"2023-12-31\", \"%Y-%m-%d\")\n",
    "\n",
    "field = \"body\"\n",
    "values = ['']\n",
    "# if you have a long list of values, you can put them in a file and put the filename here. If set this overrides the value list above\n",
    "# if this list is very large, it could greatly slow down the process\n",
    "values_file = None\n",
    "exact_match = False\n",
    "\n",
    "# sets up logging to the console as well as a file\n",
    "log = logging.getLogger(\"bot\")\n",
    "log.setLevel(logging.INFO)\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(levelname)s: %(message)s')\n",
    "log_str_handler = logging.StreamHandler()\n",
    "log_str_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_str_handler)\n",
    "if not os.path.exists(\"logs\"):\n",
    "\tos.makedirs(\"logs\")\n",
    "log_file_handler = logging.handlers.RotatingFileHandler(os.path.join(\"logs\", \"bot.log\"), maxBytes=1024*1024*16, backupCount=5)\n",
    "log_file_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_file_handler)\n",
    "\n",
    "\n",
    "def write_line_zst(handle, line):\n",
    "\thandle.write(line.encode('utf-8'))\n",
    "\thandle.write(\"\\n\".encode('utf-8'))\n",
    "\n",
    "\n",
    "def write_line_json(handle, obj):\n",
    "\thandle.write(json.dumps(obj))\n",
    "\thandle.write(\"\\n\")\n",
    "\n",
    "\n",
    "def write_line_single(handle, obj, field):\n",
    "\tif field in obj:\n",
    "\t\thandle.write(obj[field])\n",
    "\telse:\n",
    "\t\tlog.info(f\"{field} not in object {obj['id']}\")\n",
    "\thandle.write(\"\\n\")\n",
    "\n",
    "\n",
    "def write_line_csv(writer, obj, is_submission):\n",
    "    output_list = []\n",
    "    output_list.append(str(obj['score']))\n",
    "    output_list.append(datetime.fromtimestamp(int(obj['created_utc'])).strftime(\"%Y-%m-%d\"))\n",
    "    if is_submission:\n",
    "        output_list.append(obj['title'])\n",
    "        output_list.append(obj.get('num_comments', 0))  # Include num_comments for submissions\n",
    "    else:\n",
    "        output_list.append(obj.get('is_submitter', False))  # Include is_submitter for comments\n",
    "    output_list.append(f\"u/{obj['author']}\")\n",
    "    output_list.append(f\"https://www.reddit.com{obj['permalink']}\")\n",
    "    if is_submission:\n",
    "        if obj['is_self']:\n",
    "            if 'selftext' in obj:\n",
    "                output_list.append(obj['selftext'])\n",
    "            else:\n",
    "                output_list.append(\"\")\n",
    "        else:\n",
    "            output_list.append(obj['url'])\n",
    "    else:\n",
    "        output_list.append(obj['body'])\n",
    "    writer.writerow(output_list)\n",
    "\n",
    "\n",
    "def read_and_decode(reader, chunk_size, max_window_size, previous_chunk=None, bytes_read=0):\n",
    "\tchunk = reader.read(chunk_size)\n",
    "\tbytes_read += chunk_size\n",
    "\tif previous_chunk is not None:\n",
    "\t\tchunk = previous_chunk + chunk\n",
    "\ttry:\n",
    "\t\treturn chunk.decode()\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tif bytes_read > max_window_size:\n",
    "\t\t\traise UnicodeError(f\"Unable to decode frame after reading {bytes_read:,} bytes\")\n",
    "\t\tlog.info(f\"Decoding error with {bytes_read:,} bytes, reading another chunk\")\n",
    "\t\treturn read_and_decode(reader, chunk_size, max_window_size, chunk, bytes_read)\n",
    "\n",
    "\n",
    "def read_lines_zst(file_name):\n",
    "\twith open(file_name, 'rb') as file_handle:\n",
    "\t\tbuffer = ''\n",
    "\t\treader = zstandard.ZstdDecompressor(max_window_size=2**31).stream_reader(file_handle)\n",
    "\t\twhile True:\n",
    "\t\t\tchunk = read_and_decode(reader, 2**27, (2**29) * 2)\n",
    "\n",
    "\t\t\tif not chunk:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tlines = (buffer + chunk).split(\"\\n\")\n",
    "\n",
    "\t\t\tfor line in lines[:-1]:\n",
    "\t\t\t\tyield line.strip(), file_handle.tell()\n",
    "\n",
    "\t\t\tbuffer = lines[-1]\n",
    "\n",
    "\t\treader.close()\n",
    "\n",
    "\n",
    "def process_file(input_file, output_file, output_format, field, values, from_date, to_date, single_field, exact_match):\n",
    "\toutput_path = f\"{output_file}.{output_format}\"\n",
    "\tis_submission = \"submission\" in input_file\n",
    "\tlog.info(f\"Input: {input_file} : Output: {output_path} : Is submission {is_submission}\")\n",
    "\twriter = None\n",
    "\tif output_format == \"zst\":\n",
    "\t\thandle = zstandard.ZstdCompressor().stream_writer(open(output_path, 'wb'))\n",
    "\telif output_format == \"txt\":\n",
    "\t\thandle = open(output_path, 'w', encoding='UTF-8')\n",
    "\telif output_format == \"csv\":\n",
    "\t\thandle = open(output_path, 'w', encoding='UTF-8', newline='')\n",
    "\t\twriter = csv.writer(handle)\n",
    "\telse:\n",
    "\t\tlog.error(f\"Unsupported output format {output_format}\")\n",
    "\t\tsys.exit()\n",
    "\n",
    "\tfile_size = os.stat(input_file).st_size\n",
    "\tcreated = None\n",
    "\tmatched_lines = 0\n",
    "\tbad_lines = 0\n",
    "\ttotal_lines = 0\n",
    "\tfor line, file_bytes_processed in read_lines_zst(input_file):\n",
    "\t\ttotal_lines += 1\n",
    "\t\tif total_lines % 100000 == 0:\n",
    "\t\t\tlog.info(f\"{created.strftime('%Y-%m-%d %H:%M:%S')} : {total_lines:,} : {matched_lines:,} : {bad_lines:,} : {file_bytes_processed:,}:{(file_bytes_processed / file_size) * 100:.0f}%\")\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tobj = json.loads(line)\n",
    "\t\t\tcreated = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
    "\n",
    "\t\t\tif created < from_date:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif created > to_date:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif field is not None:\n",
    "\t\t\t\tfield_value = obj[field].lower()\n",
    "\t\t\t\tmatched = False\n",
    "\t\t\t\tfor value in values:\n",
    "\t\t\t\t\tif exact_match:\n",
    "\t\t\t\t\t\tif value == field_value:\n",
    "\t\t\t\t\t\t\tmatched = True\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif value in field_value:\n",
    "\t\t\t\t\t\t\tmatched = True\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\tif not matched:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tmatched_lines += 1\n",
    "\t\t\tif output_format == \"zst\":\n",
    "\t\t\t\twrite_line_zst(handle, line)\n",
    "\t\t\telif output_format == \"csv\":\n",
    "\t\t\t\twrite_line_csv(writer, obj, is_submission)\n",
    "\t\t\telif output_format == \"txt\":\n",
    "\t\t\t\tif single_field is not None:\n",
    "\t\t\t\t\twrite_line_single(handle, obj, single_field)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\twrite_line_json(handle, obj)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlog.info(f\"Something went wrong, invalid output format {output_format}\")\n",
    "\t\texcept (KeyError, json.JSONDecodeError) as err:\n",
    "\t\t\tbad_lines += 1\n",
    "\t\t\tif write_bad_lines:\n",
    "\t\t\t\tif isinstance(err, KeyError):\n",
    "\t\t\t\t\tlog.warning(f\"Key {field} is not in the object: {err}\")\n",
    "\t\t\t\telif isinstance(err, json.JSONDecodeError):\n",
    "\t\t\t\t\tlog.warning(f\"Line decoding failed: {err}\")\n",
    "\t\t\t\tlog.warning(line)\n",
    "\n",
    "\thandle.close()\n",
    "\tlog.info(f\"Complete : {total_lines:,} : {matched_lines:,} : {bad_lines:,}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tif single_field is not None:\n",
    "\t\tlog.info(\"Single field output mode, changing output file format to txt\")\n",
    "\t\toutput_format = \"txt\"\n",
    "\n",
    "\tif values_file is not None:\n",
    "\t\tvalues = []\n",
    "\t\twith open(values_file, 'r') as values_handle:\n",
    "\t\t\tfor value in values_handle:\n",
    "\t\t\t\tvalues.append(value.strip().lower())\n",
    "\t\tlog.info(f\"Loaded {len(values)} from values file {values_file}\")\n",
    "\telse:\n",
    "\t\tvalues = [value.lower() for value in values]  # convert to lowercase\n",
    "\n",
    "\tlog.info(f\"Filtering field: {field}\")\n",
    "\tif len(values) <= 20:\n",
    "\t\tlog.info(f\"On values: {','.join(values)}\")\n",
    "\telse:\n",
    "\t\tlog.info(f\"On values:\")\n",
    "\t\tfor value in values:\n",
    "\t\t\tlog.info(value)\n",
    "\tlog.info(f\"Exact match {('on' if exact_match else 'off')}. Single field {single_field}.\")\n",
    "\tlog.info(f\"From date {from_date.strftime('%Y-%m-%d')} to date {to_date.strftime('%Y-%m-%d')}\")\n",
    "\tlog.info(f\"Output format set to {output_format}\")\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    try:\n",
    "        if not filename.startswith(\"._\") and filename.endswith(\".zst\") and \"comments\" in filename:  # Process only zst files\n",
    "            input_file_path = os.path.join(input_folder, filename)\n",
    "            output_file_path = os.path.join(output_folder, os.path.splitext(filename)[0])  # Use output_folder here\n",
    "            process_file(input_file_path, output_file_path,output_format, field, values, from_date, to_date, single_field, exact_match)\n",
    "        else:\n",
    "            continue  # Skip files that are not comments files\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error processing file {filename}: {e}\")\n",
    "        continue  # Move on to the next file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d838f",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the path to the input file, or a folder of files to process all of\n",
    "input_folder = r\"/Volumes/Untitled/reddit/subreddits23\"\n",
    "# put the name or path to the output file. The file extension from below will be added automatically. If the input file is a folder, the output will be treated as a folder as well\n",
    "output_folder = r\"/Volumes/Untitled/reddit/subreddits23_csv\"\n",
    "# the format to output in, pick from the following options\n",
    "#   zst: same as the input, a zstandard compressed ndjson file. Can be read by the other scripts in the repo\n",
    "#   txt: an ndjson file, which is a text file with a separate json object on each line. Can be opened by any text editor\n",
    "#   csv: a comma separated value file. Can be opened by a text editor or excel\n",
    "# WARNING READ THIS: if you use txt or csv output on a large input file without filtering out most of the rows, the resulting file will be extremely large. Usually about 7 times as large as the compressed input file\n",
    "output_format = \"csv\"\n",
    "# override the above format and output only this field into a text file, one per line. Useful if you want to make a list of authors or ids. See the examples below\n",
    "# any field that's in the dump is supported, but useful ones are\n",
    "#   author: the username of the author\n",
    "#   id: the id of the submission or comment\n",
    "#   link_id: only for comments, the fullname of the submission the comment is associated with\n",
    "#   parent_id: only for comments, the fullname of the parent of the comment. Either another comment or the submission if it's top level\n",
    "single_field = None\n",
    "# the fields in the file are different depending on whether it has comments or submissions. If we're writing a csv, we need to know which fields to write.\n",
    "# set this to true to write out to the log every time there's a bad line, set to false if you're expecting only some of the lines to match the key\n",
    "write_bad_lines = True\n",
    "\n",
    "# only output items between these two dates\n",
    "from_date = datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
    "to_date = datetime.strptime(\"2023-12-31\", \"%Y-%m-%d\")\n",
    "\n",
    "field = \"selftext\"\n",
    "values = ['']\n",
    "# if you have a long list of values, you can put them in a file and put the filename here. If set this overrides the value list above\n",
    "# if this list is very large, it could greatly slow down the process\n",
    "values_file = None\n",
    "exact_match = False\n",
    "\n",
    "# sets up logging to the console as well as a file\n",
    "log = logging.getLogger(\"bot\")\n",
    "log.setLevel(logging.INFO)\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(levelname)s: %(message)s')\n",
    "log_str_handler = logging.StreamHandler()\n",
    "log_str_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_str_handler)\n",
    "if not os.path.exists(\"logs\"):\n",
    "\tos.makedirs(\"logs\")\n",
    "log_file_handler = logging.handlers.RotatingFileHandler(os.path.join(\"logs\", \"bot.log\"), maxBytes=1024*1024*16, backupCount=5)\n",
    "log_file_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_file_handler)\n",
    "\n",
    "\n",
    "def write_line_zst(handle, line):\n",
    "\thandle.write(line.encode('utf-8'))\n",
    "\thandle.write(\"\\n\".encode('utf-8'))\n",
    "\n",
    "\n",
    "def write_line_json(handle, obj):\n",
    "\thandle.write(json.dumps(obj))\n",
    "\thandle.write(\"\\n\")\n",
    "\n",
    "\n",
    "def write_line_single(handle, obj, field):\n",
    "\tif field in obj:\n",
    "\t\thandle.write(obj[field])\n",
    "\telse:\n",
    "\t\tlog.info(f\"{field} not in object {obj['id']}\")\n",
    "\thandle.write(\"\\n\")\n",
    "\n",
    "\n",
    "def write_line_csv(writer, obj, is_submission):\n",
    "    output_list = []\n",
    "    output_list.append(str(obj['score']))\n",
    "    output_list.append(datetime.fromtimestamp(int(obj['created_utc'])).strftime(\"%Y-%m-%d\"))\n",
    "    if is_submission:\n",
    "        output_list.append(obj['title'])\n",
    "        output_list.append(obj.get('num_comments', 0))  # Include num_comments for submissions\n",
    "    else:\n",
    "        output_list.append(obj.get('is_submitter', False))  # Include is_submitter for comments\n",
    "    output_list.append(f\"u/{obj['author']}\")\n",
    "    output_list.append(f\"https://www.reddit.com{obj['permalink']}\")\n",
    "    if is_submission:\n",
    "        if obj['is_self']:\n",
    "            if 'selftext' in obj:\n",
    "                output_list.append(obj['selftext'])\n",
    "            else:\n",
    "                output_list.append(\"\")\n",
    "        else:\n",
    "            output_list.append(obj['url'])\n",
    "    else:\n",
    "        output_list.append(obj['body'])\n",
    "    writer.writerow(output_list)\n",
    "\n",
    "\n",
    "def read_and_decode(reader, chunk_size, max_window_size, previous_chunk=None, bytes_read=0):\n",
    "\tchunk = reader.read(chunk_size)\n",
    "\tbytes_read += chunk_size\n",
    "\tif previous_chunk is not None:\n",
    "\t\tchunk = previous_chunk + chunk\n",
    "\ttry:\n",
    "\t\treturn chunk.decode()\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tif bytes_read > max_window_size:\n",
    "\t\t\traise UnicodeError(f\"Unable to decode frame after reading {bytes_read:,} bytes\")\n",
    "\t\tlog.info(f\"Decoding error with {bytes_read:,} bytes, reading another chunk\")\n",
    "\t\treturn read_and_decode(reader, chunk_size, max_window_size, chunk, bytes_read)\n",
    "\n",
    "\n",
    "def read_lines_zst(file_name):\n",
    "\twith open(file_name, 'rb') as file_handle:\n",
    "\t\tbuffer = ''\n",
    "\t\treader = zstandard.ZstdDecompressor(max_window_size=2**31).stream_reader(file_handle)\n",
    "\t\twhile True:\n",
    "\t\t\tchunk = read_and_decode(reader, 2**27, (2**29) * 2)\n",
    "\n",
    "\t\t\tif not chunk:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tlines = (buffer + chunk).split(\"\\n\")\n",
    "\n",
    "\t\t\tfor line in lines[:-1]:\n",
    "\t\t\t\tyield line.strip(), file_handle.tell()\n",
    "\n",
    "\t\t\tbuffer = lines[-1]\n",
    "\n",
    "\t\treader.close()\n",
    "\n",
    "\n",
    "def process_file(input_file, output_file, output_format, field, values, from_date, to_date, single_field, exact_match):\n",
    "\toutput_path = f\"{output_file}.{output_format}\"\n",
    "\tis_submission = \"submission\" in input_file\n",
    "\tlog.info(f\"Input: {input_file} : Output: {output_path} : Is submission {is_submission}\")\n",
    "\twriter = None\n",
    "\tif output_format == \"zst\":\n",
    "\t\thandle = zstandard.ZstdCompressor().stream_writer(open(output_path, 'wb'))\n",
    "\telif output_format == \"txt\":\n",
    "\t\thandle = open(output_path, 'w', encoding='UTF-8')\n",
    "\telif output_format == \"csv\":\n",
    "\t\thandle = open(output_path, 'w', encoding='UTF-8', newline='')\n",
    "\t\twriter = csv.writer(handle)\n",
    "\telse:\n",
    "\t\tlog.error(f\"Unsupported output format {output_format}\")\n",
    "\t\tsys.exit()\n",
    "\n",
    "\tfile_size = os.stat(input_file).st_size\n",
    "\tcreated = None\n",
    "\tmatched_lines = 0\n",
    "\tbad_lines = 0\n",
    "\ttotal_lines = 0\n",
    "\tfor line, file_bytes_processed in read_lines_zst(input_file):\n",
    "\t\ttotal_lines += 1\n",
    "\t\tif total_lines % 100000 == 0:\n",
    "\t\t\tlog.info(f\"{created.strftime('%Y-%m-%d %H:%M:%S')} : {total_lines:,} : {matched_lines:,} : {bad_lines:,} : {file_bytes_processed:,}:{(file_bytes_processed / file_size) * 100:.0f}%\")\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tobj = json.loads(line)\n",
    "\t\t\tcreated = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
    "\n",
    "\t\t\tif created < from_date:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif created > to_date:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif field is not None:\n",
    "\t\t\t\tfield_value = obj[field].lower()\n",
    "\t\t\t\tmatched = False\n",
    "\t\t\t\tfor value in values:\n",
    "\t\t\t\t\tif exact_match:\n",
    "\t\t\t\t\t\tif value == field_value:\n",
    "\t\t\t\t\t\t\tmatched = True\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif value in field_value:\n",
    "\t\t\t\t\t\t\tmatched = True\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\tif not matched:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tmatched_lines += 1\n",
    "\t\t\tif output_format == \"zst\":\n",
    "\t\t\t\twrite_line_zst(handle, line)\n",
    "\t\t\telif output_format == \"csv\":\n",
    "\t\t\t\twrite_line_csv(writer, obj, is_submission)\n",
    "\t\t\telif output_format == \"txt\":\n",
    "\t\t\t\tif single_field is not None:\n",
    "\t\t\t\t\twrite_line_single(handle, obj, single_field)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\twrite_line_json(handle, obj)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlog.info(f\"Something went wrong, invalid output format {output_format}\")\n",
    "\t\texcept (KeyError, json.JSONDecodeError) as err:\n",
    "\t\t\tbad_lines += 1\n",
    "\t\t\tif write_bad_lines:\n",
    "\t\t\t\tif isinstance(err, KeyError):\n",
    "\t\t\t\t\tlog.warning(f\"Key {field} is not in the object: {err}\")\n",
    "\t\t\t\telif isinstance(err, json.JSONDecodeError):\n",
    "\t\t\t\t\tlog.warning(f\"Line decoding failed: {err}\")\n",
    "\t\t\t\tlog.warning(line)\n",
    "\n",
    "\thandle.close()\n",
    "\tlog.info(f\"Complete : {total_lines:,} : {matched_lines:,} : {bad_lines:,}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tif single_field is not None:\n",
    "\t\tlog.info(\"Single field output mode, changing output file format to txt\")\n",
    "\t\toutput_format = \"txt\"\n",
    "\n",
    "\tif values_file is not None:\n",
    "\t\tvalues = []\n",
    "\t\twith open(values_file, 'r') as values_handle:\n",
    "\t\t\tfor value in values_handle:\n",
    "\t\t\t\tvalues.append(value.strip().lower())\n",
    "\t\tlog.info(f\"Loaded {len(values)} from values file {values_file}\")\n",
    "\telse:\n",
    "\t\tvalues = [value.lower() for value in values]  # convert to lowercase\n",
    "\n",
    "\tlog.info(f\"Filtering field: {field}\")\n",
    "\tif len(values) <= 20:\n",
    "\t\tlog.info(f\"On values: {','.join(values)}\")\n",
    "\telse:\n",
    "\t\tlog.info(f\"On values:\")\n",
    "\t\tfor value in values:\n",
    "\t\t\tlog.info(value)\n",
    "\tlog.info(f\"Exact match {('on' if exact_match else 'off')}. Single field {single_field}.\")\n",
    "\tlog.info(f\"From date {from_date.strftime('%Y-%m-%d')} to date {to_date.strftime('%Y-%m-%d')}\")\n",
    "\tlog.info(f\"Output format set to {output_format}\")\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    try:\n",
    "        if not filename.startswith(\"._\") and filename.endswith(\".zst\") and \"submissions\" in filename:  # Process only zst files\n",
    "            input_file_path = os.path.join(input_folder, filename)\n",
    "            output_file_path = os.path.join(output_folder, os.path.splitext(filename)[0])  # Use output_folder here\n",
    "            process_file(input_file_path, output_file_path,output_format, field, values, from_date, to_date, single_field, exact_match)\n",
    "        else:\n",
    "            continue  # Skip files that are not comments files\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error processing file {filename}: {e}\")\n",
    "        continue  # Move on to the next file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc777fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find zero byte files in subreddits23_csv and save as list \n",
    "import os\n",
    "import csv\n",
    "\n",
    "path = r\"/Volumes/Untitled/reddit/subreddits23_csv\"\n",
    "zero_byte_files = []\n",
    "for filename in os.listdir(path):\n",
    "    if os.path.getsize(os.path.join(path, filename)) == 0:\n",
    "        zero_byte_files.append(filename)\n",
    "zero_byte_files\n",
    "\n",
    "# remove \".csv\" from the end of each file name\n",
    "zero_byte_files = [file[:-4] for file in zero_byte_files]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a324e526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['badukpolitics_comments',\n",
       " 'bbcnewsuk_comments',\n",
       " 'BritishNationalism_comments',\n",
       " 'CCTVCamerasUK_comments',\n",
       " 'DailyMail_comments',\n",
       " 'fakeIDUK_comments',\n",
       " 'thebritishelites_comments',\n",
       " 'Ukhempflowers_comments',\n",
       " 'ukpolitics_comments',\n",
       " 'UKTVLAND_comments',\n",
       " 'UKNewsByABot_submissions',\n",
       " 'uk_news_today_submissions',\n",
       " 'badukpolitics_submissions',\n",
       " 'bbcnewsuk_submissions',\n",
       " 'BritishNationalism_submissions',\n",
       " 'CCTVCamerasUK_submissions',\n",
       " 'DailyMail_submissions',\n",
       " 'fakeIDUK_submissions',\n",
       " 'thebritishelites_submissions',\n",
       " 'Ukhempflowers_submissions',\n",
       " 'UKTVLAND_submissions']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_byte_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "445c0614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero_byte_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14cf2df",
   "metadata": {},
   "source": [
    "For these files, I need to go through the terminal to decompress them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02a1ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zstd -d /Volumes/Untitled/reddit/subreddits23/badukpolitics_comments.zst -o badukpolitics_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/bbcnewsuk_comments.zst -o bbcnewsuk_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/BritishNationalism_comments.zst -o BritishNationalism_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/CCTVCamerasUK_comments.zst -o CCTVCamerasUK_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/DailyMail_comments.zst -o DailyMail_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/fakeIDUK_comments.zst -o fakeIDUK_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/thebritishelites_comments.zst -o thebritishelites_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/Ukhempflowers_comments.zst -o Ukhempflowers_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/ukpolitics_comments.zst -o ukpolitics_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/UKTVLAND_comments.zst -o UKTVLAND_comments.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/UKNewsByABot_submissions.zst -o UKNewsByABot_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/uk_news_today_submissions.zst -o uk_news_today_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/badukpolitics_submissions.zst -o badukpolitics_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/bbcnewsuk_submissions.zst -o bbcnewsuk_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/BritishNationalism_submissions.zst -o BritishNationalism_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/CCTVCamerasUK_submissions.zst -o CCTVCamerasUK_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/DailyMail_submissions.zst -o DailyMail_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/fakeIDUK_submissions.zst -o fakeIDUK_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/thebritishelites_submissions.zst -o thebritishelites_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/Ukhempflowers_submissions.zst -o Ukhempflowers_submissions.txt\n",
      "zstd -d /Volumes/Untitled/reddit/subreddits23/UKTVLAND_submissions.zst -o UKTVLAND_submissions.txt\n"
     ]
    }
   ],
   "source": [
    "# printing commands to copy paste into terminal \n",
    "for file in zero_byte_files:\n",
    "    print(f\"zstd -d /Volumes/Untitled/reddit/subreddits23/{file}.zst -o {file}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0ba7086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv ~/badukpolitics_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/bbcnewsuk_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/BritishNationalism_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/CCTVCamerasUK_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/DailyMail_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/fakeIDUK_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/thebritishelites_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/Ukhempflowers_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/ukpolitics_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/UKTVLAND_comments.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/UKNewsByABot_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/uk_news_today_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/badukpolitics_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/bbcnewsuk_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/BritishNationalism_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/CCTVCamerasUK_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/DailyMail_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/fakeIDUK_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/thebritishelites_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/Ukhempflowers_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n",
      "mv ~/UKTVLAND_submissions.txt /Volumes/Untitled/reddit/zerobyte_files/\n"
     ]
    }
   ],
   "source": [
    "# printing commands to copy paste into terminal and move files to zerobyte_files folder\n",
    "for file in zero_byte_files:\n",
    "    print(f\"mv ~/{file}.txt /Volumes/Untitled/reddit/zerobyte_files/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab278d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert zero byte files to CSV\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the directory containing the .txt files and the output directory\n",
    "input_directory = \"/Volumes/Untitled/reddit/zerobyte_files/\"\n",
    "output_directory = \"/Volumes/Untitled/reddit/zerobyte_files_csv/\"\n",
    "\n",
    "# Define the fields to include in the CSV\n",
    "csv_fields = [\n",
    "    \"score\", \n",
    "    \"created_utc\", \n",
    "    \"author\", \n",
    "    \"permalink\", \n",
    "    \"body\", \n",
    "    \"is_submitter\", \n",
    "    \"num_comments\", \n",
    "    \"title\", \n",
    "    \"url\"\n",
    "]\n",
    "\n",
    "def parse_json_line(line):\n",
    "    try:\n",
    "        obj = json.loads(line)\n",
    "        created = datetime.utcfromtimestamp(int(obj['created_utc'])).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        csv_row = {\n",
    "            \"score\": obj.get(\"score\", \"\"),\n",
    "            \"created_utc\": created,\n",
    "            \"author\": f\"u/{obj.get('author', '')}\",\n",
    "            \"permalink\": f\"https://www.reddit.com{obj.get('permalink', '')}\",\n",
    "            \"body\": obj.get(\"body\", \"\"),\n",
    "            \"is_submitter\": obj.get(\"is_submitter\", \"\"),\n",
    "            \"num_comments\": obj.get(\"num_comments\", \"\"),\n",
    "            \"title\": obj.get(\"title\", \"\"),\n",
    "            \"url\": obj.get(\"url\", \"\")\n",
    "        }\n",
    "        \n",
    "        return csv_row\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def read_and_convert(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='latin-1') as infile, open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=csv_fields)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for line in infile:\n",
    "            csv_row = parse_json_line(line.strip())\n",
    "            if csv_row:\n",
    "                writer.writerow(csv_row)\n",
    "\n",
    "# Process all .txt files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_file_path = os.path.join(input_directory, filename)\n",
    "        output_file_name = filename.replace(\".txt\", \".csv\")\n",
    "        output_file_path = os.path.join(output_directory, output_file_name)\n",
    "        \n",
    "        print(f\"Processing {input_file_path} to {output_file_path}\")\n",
    "        read_and_convert(input_file_path, output_file_path)\n",
    "\n",
    "print(\"All files processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_path = r\"/Volumes/Untitled/reddit/subreddits23_csv\"\n",
    "output_path = r\"/Volumes/Untitled/reddit/cleaned_subreddits\"\n",
    "\n",
    "for filename in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, filename)\n",
    "    \n",
    "    # skip processing if the file is zero bytes (separate cleaning process for these files)\n",
    "    if os.path.getsize(file_path) == 0:\n",
    "        continue\n",
    "\n",
    "    if \"comments\" in filename:\n",
    "        column_names = ['score', 'date', 'is_submitter', 'user', 'link', 'body']\n",
    "    else:\n",
    "        # column names for submissions\n",
    "        column_names = ['score', 'date', 'title', 'num_comments', 'user', 'link', 'body']\n",
    "    \n",
    "    # read csv file with specified column names\n",
    "    df = pd.read_csv(file_path, names=column_names, header=None, encoding='ISO-8859-1')\n",
    "    \n",
    "    # check if all columns are present\n",
    "    if not all(col in df.columns for col in column_names):\n",
    "        print(f\"Skipping {filename} due to missing columns\")\n",
    "        continue\n",
    "\n",
    "    if \"comments\" in filename:\n",
    "        # add a column for is_comment\n",
    "        df['is_comment'] = 1\n",
    "    else:\n",
    "        # add a column for is_comment\n",
    "        df['is_comment'] = 0\n",
    "    \n",
    "    # remove rows where 'user' is \"u/[deleted]\"\n",
    "    df = df[~df['user'].isin([\"u/[deleted]\"])]\n",
    "    \n",
    "    # remove rows where 'body' is \"[deleted]\", \"[removed]\", or empty\n",
    "    df = df[~df['body'].isin([\"[deleted]\", \"[removed]\", \"\"])]\n",
    "    \n",
    "    # remove rows where 'body' has only one word\n",
    "    df = df[df['body'].apply(lambda x: len(str(x).split()) > 1)]\n",
    "    \n",
    "    # change 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    \n",
    "    # add a column for subreddit\n",
    "    df['subreddit'] = filename.split(\"_\")[0]\n",
    "    \n",
    "    # save cleaned file to cleaned_subreddits folder\n",
    "    cleaned_file_path = os.path.join(output_path, filename)\n",
    "    df.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"Saved {filename} to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "002b839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved thebritishelites_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits/thebritishelites_comments.csv\n",
      "Saved ._thebritishelites_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits/._thebritishelites_comments.csv\n",
      "Saved thebritishelites_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits/thebritishelites_submissions.csv\n",
      "Saved ._thebritishelites_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits/._thebritishelites_submissions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "## now to handle files in zero_bytes folder\n",
    "## they have 0kb in subreddit23_csv folder and were processed separately and moved to zero_bytes folder\n",
    "input_path = r\"/Volumes/Untitled/reddit/zerobyte_files\"\n",
    "output_path = r\"/Volumes/Untitled/reddit/cleaned_subreddits\"\n",
    "csv_fields = [\n",
    "    \"score\", \n",
    "    \"created_utc\", \n",
    "    \"author\", \n",
    "    \"permalink\", \n",
    "    \"body\", \n",
    "    \"is_submitter\", \n",
    "    \"num_comments\", \n",
    "    \"title\", \n",
    "    \"url\"\n",
    "]\n",
    "for filename in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, filename)\n",
    "    df = pd.read_csv(file_path, names= csv_fields, encoding='utf-8')\n",
    "    if \"comments\" in filename:\n",
    "        # drop uneccessary columns\n",
    "        df.drop(columns=[\"is_submitter\", \"num_comments\", \"title\", \"url\"], inplace=True)\n",
    "        df.columns = ['score', 'date', 'user', 'link', 'body']\n",
    "    else:\n",
    "        # drop uneccessary columns\n",
    "        df.drop(columns=[\"body\", \"is_submitter\"], inplace=True)\n",
    "        # column names for submissions\n",
    "        df.columns = ['score', 'date', 'user', 'link', 'num_comments', 'title', 'body']\n",
    "    \n",
    "    # add a column for is_comment\n",
    "    if \"comments\" in filename:\n",
    "        # add a column for is_comment\n",
    "        df['is_comment'] = 1\n",
    "    else:\n",
    "        # add a column for is_comment\n",
    "        df['is_comment'] = 0\n",
    "    \n",
    "    # add a column for subreddit\n",
    "    df['subreddit'] = filename.split(\"_\")[0]\n",
    "    \n",
    "    # remove rows where 'user' is \"u/[deleted]\"\n",
    "    df = df[~df['user'].isin([\"u/[deleted]\"])]\n",
    "\n",
    "    # remove rows where 'body' is \"[deleted]\", \"[removed]\", or empty\n",
    "    df = df[~df['body'].isin([\"[deleted]\", \"[removed]\", \"\"])]\n",
    "\n",
    "    # remove rows where 'body' has only one word\n",
    "    df = df[df['body'].apply(lambda x: len(str(x).split()) > 1)]\n",
    "\n",
    "    # change 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    # save cleaned file to cleaned_subreddits folder\n",
    "    cleaned_file_path = os.path.join(output_path, filename)\n",
    "    df.to_csv(cleaned_file_path, index=False)\n",
    "    \n",
    "    print(f\"Saved {filename} to {cleaned_file_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aede9ea",
   "metadata": {},
   "source": [
    "## Filtering comments about immigration\n",
    "- had to generate exhaustive list of keywords using GPT4\n",
    "- had to respecify column names based on whether file was a comment or submission\n",
    "- specified body as a string type and moved to first index position (because body is in different positions depending on csv so to make it consistent when subsetting based on column value)\n",
    "- filtered based on keywords and saved  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ada88cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: leicester_comments.csv\n",
      "Saved leicester_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/leicester_comments.csv\n",
      "Processing file: ._leicester_comments.csv\n",
      "Saved ._leicester_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._leicester_comments.csv\n",
      "Processing file: ukeducation_comments.csv\n",
      "Saved ukeducation_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukeducation_comments.csv\n",
      "Processing file: ._ukeducation_comments.csv\n",
      "Saved ._ukeducation_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukeducation_comments.csv\n",
      "Processing file: medicalschooluk_comments.csv\n",
      "Saved medicalschooluk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/medicalschooluk_comments.csv\n",
      "Processing file: ._medicalschooluk_comments.csv\n",
      "Saved ._medicalschooluk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._medicalschooluk_comments.csv\n",
      "Processing file: apprenticeuk_comments.csv\n",
      "Saved apprenticeuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/apprenticeuk_comments.csv\n",
      "Processing file: ._apprenticeuk_comments.csv\n",
      "Saved ._apprenticeuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._apprenticeuk_comments.csv\n",
      "Processing file: AskABrit_comments.csv\n",
      "Saved AskABrit_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/AskABrit_comments.csv\n",
      "Processing file: ._AskABrit_comments.csv\n",
      "Saved ._AskABrit_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._AskABrit_comments.csv\n",
      "Processing file: baduk_comments.csv\n",
      "Saved baduk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/baduk_comments.csv\n",
      "Processing file: ._baduk_comments.csv\n",
      "Saved ._baduk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._baduk_comments.csv\n",
      "Processing file: bbuk_comments.csv\n",
      "Saved bbuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/bbuk_comments.csv\n",
      "Processing file: ._bbuk_comments.csv\n",
      "Saved ._bbuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._bbuk_comments.csv\n",
      "Processing file: beermoneyuk_comments.csv\n",
      "Saved beermoneyuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/beermoneyuk_comments.csv\n",
      "Processing file: ._beermoneyuk_comments.csv\n",
      "Saved ._beermoneyuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._beermoneyuk_comments.csv\n",
      "Processing file: BeyondTheBumpUK_comments.csv\n",
      "Saved BeyondTheBumpUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/BeyondTheBumpUK_comments.csv\n",
      "Processing file: ._BeyondTheBumpUK_comments.csv\n",
      "Saved ._BeyondTheBumpUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BeyondTheBumpUK_comments.csv\n",
      "Processing file: bigbrotheruk_comments.csv\n",
      "Saved bigbrotheruk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/bigbrotheruk_comments.csv\n",
      "Processing file: ._bigbrotheruk_comments.csv\n",
      "Saved ._bigbrotheruk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._bigbrotheruk_comments.csv\n",
      "Processing file: BirminghamUK_comments.csv\n",
      "Saved BirminghamUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/BirminghamUK_comments.csv\n",
      "Processing file: ._BirminghamUK_comments.csv\n",
      "Saved ._BirminghamUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BirminghamUK_comments.csv\n",
      "Processing file: Britain_comments.csv\n",
      "Saved Britain_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/Britain_comments.csv\n",
      "Processing file: ._Britain_comments.csv\n",
      "Saved ._Britain_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Britain_comments.csv\n",
      "Processing file: britisharmy_comments.csv\n",
      "Saved britisharmy_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/britisharmy_comments.csv\n",
      "Processing file: ._britisharmy_comments.csv\n",
      "Saved ._britisharmy_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britisharmy_comments.csv\n",
      "Processing file: britishmilitary_comments.csv\n",
      "Saved britishmilitary_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/britishmilitary_comments.csv\n",
      "Processing file: ._britishmilitary_comments.csv\n",
      "Saved ._britishmilitary_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britishmilitary_comments.csv\n",
      "Processing file: britishproblems_comments.csv\n",
      "Saved britishproblems_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/britishproblems_comments.csv\n",
      "Processing file: ._britishproblems_comments.csv\n",
      "Saved ._britishproblems_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britishproblems_comments.csv\n",
      "Processing file: BritishSuccess_comments.csv\n",
      "Saved BritishSuccess_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/BritishSuccess_comments.csv\n",
      "Processing file: ._BritishSuccess_comments.csv\n",
      "Saved ._BritishSuccess_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BritishSuccess_comments.csv\n",
      "Processing file: BritishTV_comments.csv\n",
      "Saved BritishTV_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/BritishTV_comments.csv\n",
      "Processing file: ._BritishTV_comments.csv\n",
      "Saved ._BritishTV_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BritishTV_comments.csv\n",
      "Processing file: britpics_comments.csv\n",
      "Saved britpics_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/britpics_comments.csv\n",
      "Processing file: ._britpics_comments.csv\n",
      "Saved ._britpics_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britpics_comments.csv\n",
      "Processing file: britposting_comments.csv\n",
      "Saved britposting_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/britposting_comments.csv\n",
      "Processing file: ._britposting_comments.csv\n",
      "Saved ._britposting_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britposting_comments.csv\n",
      "Processing file: buildapcsalesuk_comments.csv\n",
      "Saved buildapcsalesuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/buildapcsalesuk_comments.csv\n",
      "Processing file: ._buildapcsalesuk_comments.csv\n",
      "Saved ._buildapcsalesuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._buildapcsalesuk_comments.csv\n",
      "Processing file: CANZUK_comments.csv\n",
      "Saved CANZUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/CANZUK_comments.csv\n",
      "Processing file: ._CANZUK_comments.csv\n",
      "Saved ._CANZUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CANZUK_comments.csv\n",
      "Processing file: CarTalkUK_comments.csv\n",
      "Saved CarTalkUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/CarTalkUK_comments.csv\n",
      "Processing file: ._CarTalkUK_comments.csv\n",
      "Saved ._CarTalkUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CarTalkUK_comments.csv\n",
      "Processing file: CasualUK_comments.csv\n",
      "Saved CasualUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/CasualUK_comments.csv\n",
      "Processing file: ._CasualUK_comments.csv\n",
      "Saved ._CasualUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CasualUK_comments.csv\n",
      "Processing file: CBDFlowerUK_comments.csv\n",
      "Saved CBDFlowerUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/CBDFlowerUK_comments.csv\n",
      "Processing file: ._CBDFlowerUK_comments.csv\n",
      "Saved ._CBDFlowerUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CBDFlowerUK_comments.csv\n",
      "Processing file: ChatSwapMeetDevonUK_comments.csv\n",
      "Saved ChatSwapMeetDevonUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ChatSwapMeetDevonUK_comments.csv\n",
      "Processing file: ._ChatSwapMeetDevonUK_comments.csv\n",
      "Saved ._ChatSwapMeetDevonUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ChatSwapMeetDevonUK_comments.csv\n",
      "Processing file: ContractorUK_comments.csv\n",
      "Saved ContractorUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ContractorUK_comments.csv\n",
      "Processing file: ._ContractorUK_comments.csv\n",
      "Saved ._ContractorUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ContractorUK_comments.csv\n",
      "Processing file: CoronavirusUK_comments.csv\n",
      "Saved CoronavirusUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/CoronavirusUK_comments.csv\n",
      "Processing file: ._CoronavirusUK_comments.csv\n",
      "Saved ._CoronavirusUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CoronavirusUK_comments.csv\n",
      "Processing file: CurlyHairUK_comments.csv\n",
      "Saved CurlyHairUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/CurlyHairUK_comments.csv\n",
      "Processing file: ._CurlyHairUK_comments.csv\n",
      "Saved ._CurlyHairUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CurlyHairUK_comments.csv\n",
      "Processing file: DIYUK_comments.csv\n",
      "Saved DIYUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/DIYUK_comments.csv\n",
      "Processing file: ._DIYUK_comments.csv\n",
      "Saved ._DIYUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._DIYUK_comments.csv\n",
      "Processing file: doctorsUK_comments.csv\n",
      "Saved doctorsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/doctorsUK_comments.csv\n",
      "Processing file: ._doctorsUK_comments.csv\n",
      "Saved ._doctorsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._doctorsUK_comments.csv\n",
      "Processing file: drivingUK_comments.csv\n",
      "Saved drivingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/drivingUK_comments.csv\n",
      "Processing file: ._drivingUK_comments.csv\n",
      "Saved ._drivingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._drivingUK_comments.csv\n",
      "Processing file: FIREUK_comments.csv\n",
      "Saved FIREUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/FIREUK_comments.csv\n",
      "Processing file: ._FIREUK_comments.csv\n",
      "Saved ._FIREUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._FIREUK_comments.csv\n",
      "Processing file: foraginguk_comments.csv\n",
      "Saved foraginguk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/foraginguk_comments.csv\n",
      "Processing file: ._foraginguk_comments.csv\n",
      "Saved ._foraginguk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._foraginguk_comments.csv\n",
      "Processing file: GardeningUK_comments.csv\n",
      "Saved GardeningUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/GardeningUK_comments.csv\n",
      "Processing file: ._GardeningUK_comments.csv\n",
      "Saved ._GardeningUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._GardeningUK_comments.csv\n",
      "Processing file: Gayuklads_comments.csv\n",
      "Saved Gayuklads_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/Gayuklads_comments.csv\n",
      "Processing file: ._Gayuklads_comments.csv\n",
      "Saved ._Gayuklads_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Gayuklads_comments.csv\n",
      "Processing file: Gayuksnapchat_comments.csv\n",
      "Saved Gayuksnapchat_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/Gayuksnapchat_comments.csv\n",
      "Processing file: ._Gayuksnapchat_comments.csv\n",
      "Saved ._Gayuksnapchat_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Gayuksnapchat_comments.csv\n",
      "Processing file: hanguk_comments.csv\n",
      "Saved hanguk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/hanguk_comments.csv\n",
      "Processing file: ._hanguk_comments.csv\n",
      "Saved ._hanguk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._hanguk_comments.csv\n",
      "Processing file: heyUK_comments.csv\n",
      "Saved heyUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/heyUK_comments.csv\n",
      "Processing file: ._heyUK_comments.csv\n",
      "Saved ._heyUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._heyUK_comments.csv\n",
      "Processing file: HorseRacingUK_comments.csv\n",
      "Saved HorseRacingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/HorseRacingUK_comments.csv\n",
      "Processing file: ._HorseRacingUK_comments.csv\n",
      "Saved ._HorseRacingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._HorseRacingUK_comments.csv\n",
      "Processing file: HouseplantsUK_comments.csv\n",
      "Saved HouseplantsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/HouseplantsUK_comments.csv\n",
      "Processing file: ._HouseplantsUK_comments.csv\n",
      "Saved ._HouseplantsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._HouseplantsUK_comments.csv\n",
      "Processing file: hwsukrep_comments.csv\n",
      "Saved hwsukrep_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/hwsukrep_comments.csv\n",
      "Processing file: ._hwsukrep_comments.csv\n",
      "Saved ._hwsukrep_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._hwsukrep_comments.csv\n",
      "Processing file: JustEatUK_comments.csv\n",
      "Saved JustEatUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/JustEatUK_comments.csv\n",
      "Processing file: ._JustEatUK_comments.csv\n",
      "Saved ._JustEatUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._JustEatUK_comments.csv\n",
      "Processing file: kentuk_comments.csv\n",
      "Saved kentuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/kentuk_comments.csv\n",
      "Processing file: ._kentuk_comments.csv\n",
      "Saved ._kentuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._kentuk_comments.csv\n",
      "Processing file: ketouk_comments.csv\n",
      "Saved ketouk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ketouk_comments.csv\n",
      "Processing file: ._ketouk_comments.csv\n",
      "Saved ._ketouk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ketouk_comments.csv\n",
      "Processing file: LearnerDriverUK_comments.csv\n",
      "Saved LearnerDriverUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/LearnerDriverUK_comments.csv\n",
      "Processing file: ._LearnerDriverUK_comments.csv\n",
      "Saved ._LearnerDriverUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._LearnerDriverUK_comments.csv\n",
      "Processing file: MAFS_UK_comments.csv\n",
      "Saved MAFS_UK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/MAFS_UK_comments.csv\n",
      "Processing file: ._MAFS_UK_comments.csv\n",
      "Saved ._MAFS_UK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MAFS_UK_comments.csv\n",
      "Processing file: MagicMushroomsUK_comments.csv\n",
      "Saved MagicMushroomsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/MagicMushroomsUK_comments.csv\n",
      "Processing file: ._MagicMushroomsUK_comments.csv\n",
      "Saved ._MagicMushroomsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MagicMushroomsUK_comments.csv\n",
      "Processing file: MakeUpAddictionUK_comments.csv\n",
      "Saved MakeUpAddictionUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/MakeUpAddictionUK_comments.csv\n",
      "Processing file: ._MakeUpAddictionUK_comments.csv\n",
      "Saved ._MakeUpAddictionUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MakeUpAddictionUK_comments.csv\n",
      "Processing file: ManchesterUKmeets_comments.csv\n",
      "Saved ManchesterUKmeets_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ManchesterUKmeets_comments.csv\n",
      "Processing file: ._ManchesterUKmeets_comments.csv\n",
      "Saved ._ManchesterUKmeets_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ManchesterUKmeets_comments.csv\n",
      "Processing file: MarriedAtFirstSightUk_comments.csv\n",
      "Saved MarriedAtFirstSightUk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/MarriedAtFirstSightUk_comments.csv\n",
      "Processing file: ._MarriedAtFirstSightUk_comments.csv\n",
      "Saved ._MarriedAtFirstSightUk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MarriedAtFirstSightUk_comments.csv\n",
      "Processing file: MentalHealthUK_comments.csv\n",
      "Saved MentalHealthUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/MentalHealthUK_comments.csv\n",
      "Processing file: ._MentalHealthUK_comments.csv\n",
      "Saved ._MentalHealthUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MentalHealthUK_comments.csv\n",
      "Processing file: Mortgageadviceuk_comments.csv\n",
      "Saved Mortgageadviceuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/Mortgageadviceuk_comments.csv\n",
      "Processing file: ._Mortgageadviceuk_comments.csv\n",
      "Saved ._Mortgageadviceuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Mortgageadviceuk_comments.csv\n",
      "Processing file: NewsOfTheUK_comments.csv\n",
      "Saved NewsOfTheUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/NewsOfTheUK_comments.csv\n",
      "Processing file: ._NewsOfTheUK_comments.csv\n",
      "Saved ._NewsOfTheUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._NewsOfTheUK_comments.csv\n",
      "Processing file: NFLUK_comments.csv\n",
      "Saved NFLUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/NFLUK_comments.csv\n",
      "Processing file: ._NFLUK_comments.csv\n",
      "Saved ._NFLUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._NFLUK_comments.csv\n",
      "Processing file: NursingUK_comments.csv\n",
      "Saved NursingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/NursingUK_comments.csv\n",
      "Processing file: ._NursingUK_comments.csv\n",
      "Saved ._NursingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._NursingUK_comments.csv\n",
      "Processing file: OrnithologyUK_comments.csv\n",
      "Saved OrnithologyUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/OrnithologyUK_comments.csv\n",
      "Processing file: ._OrnithologyUK_comments.csv\n",
      "Saved ._OrnithologyUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._OrnithologyUK_comments.csv\n",
      "Processing file: policeuk_comments.csv\n",
      "Saved policeuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/policeuk_comments.csv\n",
      "Processing file: ._policeuk_comments.csv\n",
      "Saved ._policeuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._policeuk_comments.csv\n",
      "Processing file: PregnancyUK_comments.csv\n",
      "Saved PregnancyUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/PregnancyUK_comments.csv\n",
      "Processing file: ._PregnancyUK_comments.csv\n",
      "Saved ._PregnancyUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._PregnancyUK_comments.csv\n",
      "Processing file: premeduk_comments.csv\n",
      "Saved premeduk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/premeduk_comments.csv\n",
      "Processing file: ._premeduk_comments.csv\n",
      "Saved ._premeduk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._premeduk_comments.csv\n",
      "Processing file: prsuk_comments.csv\n",
      "Saved prsuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/prsuk_comments.csv\n",
      "Processing file: ._prsuk_comments.csv\n",
      "Saved ._prsuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._prsuk_comments.csv\n",
      "Processing file: RPDR_UK_comments.csv\n",
      "Saved RPDR_UK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/RPDR_UK_comments.csv\n",
      "Processing file: ._RPDR_UK_comments.csv\n",
      "Saved ._RPDR_UK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._RPDR_UK_comments.csv\n",
      "Processing file: SkincareAddictionUK_comments.csv\n",
      "Saved SkincareAddictionUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/SkincareAddictionUK_comments.csv\n",
      "Processing file: ._SkincareAddictionUK_comments.csv\n",
      "Saved ._SkincareAddictionUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._SkincareAddictionUK_comments.csv\n",
      "Processing file: smallbusinessuk_comments.csv\n",
      "Saved smallbusinessuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/smallbusinessuk_comments.csv\n",
      "Processing file: ._smallbusinessuk_comments.csv\n",
      "Saved ._smallbusinessuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._smallbusinessuk_comments.csv\n",
      "Processing file: SteroidsUK_comments.csv\n",
      "Saved SteroidsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/SteroidsUK_comments.csv\n",
      "Processing file: ._SteroidsUK_comments.csv\n",
      "Saved ._SteroidsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._SteroidsUK_comments.csv\n",
      "Processing file: superstonkuk_comments.csv\n",
      "Saved superstonkuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/superstonkuk_comments.csv\n",
      "Processing file: ._superstonkuk_comments.csv\n",
      "Saved ._superstonkuk_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._superstonkuk_comments.csv\n",
      "Processing file: transgenderUK_comments.csv\n",
      "Saved transgenderUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/transgenderUK_comments.csv\n",
      "Processing file: ._transgenderUK_comments.csv\n",
      "Saved ._transgenderUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._transgenderUK_comments.csv\n",
      "Processing file: TrapsUK_comments.csv\n",
      "Saved TrapsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/TrapsUK_comments.csv\n",
      "Processing file: ._TrapsUK_comments.csv\n",
      "Saved ._TrapsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._TrapsUK_comments.csv\n",
      "Processing file: UbereatsUK_comments.csv\n",
      "Saved UbereatsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UbereatsUK_comments.csv\n",
      "Processing file: ._UbereatsUK_comments.csv\n",
      "Saved ._UbereatsUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UbereatsUK_comments.csv\n",
      "Processing file: UK_beer_comments.csv\n",
      "Saved UK_beer_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UK_beer_comments.csv\n",
      "Processing file: ._UK_beer_comments.csv\n",
      "Saved ._UK_beer_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UK_beer_comments.csv\n",
      "Processing file: UK_Food_comments.csv\n",
      "Saved UK_Food_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UK_Food_comments.csv\n",
      "Processing file: ._UK_Food_comments.csv\n",
      "Saved ._UK_Food_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UK_Food_comments.csv\n",
      "Processing file: UK_Pets_comments.csv\n",
      "Saved UK_Pets_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UK_Pets_comments.csv\n",
      "Processing file: ._UK_Pets_comments.csv\n",
      "Saved ._UK_Pets_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UK_Pets_comments.csv\n",
      "Processing file: UKbands_comments.csv\n",
      "Saved UKbands_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKbands_comments.csv\n",
      "Processing file: ._UKbands_comments.csv\n",
      "Saved ._UKbands_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKbands_comments.csv\n",
      "Processing file: UKBBQ_comments.csv\n",
      "Saved UKBBQ_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKBBQ_comments.csv\n",
      "Processing file: ._UKBBQ_comments.csv\n",
      "Saved ._UKBBQ_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKBBQ_comments.csv\n",
      "Processing file: ukbike_comments.csv\n",
      "Saved ukbike_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukbike_comments.csv\n",
      "Processing file: ._ukbike_comments.csv\n",
      "Saved ._ukbike_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukbike_comments.csv\n",
      "Processing file: UKbills_comments.csv\n",
      "Saved UKbills_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKbills_comments.csv\n",
      "Processing file: ._UKbills_comments.csv\n",
      "Saved ._UKbills_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKbills_comments.csv\n",
      "Processing file: ukcigars_comments.csv\n",
      "Saved ukcigars_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukcigars_comments.csv\n",
      "Processing file: ._ukcigars_comments.csv\n",
      "Saved ._ukcigars_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukcigars_comments.csv\n",
      "Processing file: UKcoins_comments.csv\n",
      "Saved UKcoins_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKcoins_comments.csv\n",
      "Processing file: ._UKcoins_comments.csv\n",
      "Saved ._UKcoins_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKcoins_comments.csv\n",
      "Processing file: UKDota_comments.csv\n",
      "Saved UKDota_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKDota_comments.csv\n",
      "Processing file: ._UKDota_comments.csv\n",
      "Saved ._UKDota_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKDota_comments.csv\n",
      "Processing file: ukdrill_comments.csv\n",
      "Saved ukdrill_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukdrill_comments.csv\n",
      "Processing file: ._ukdrill_comments.csv\n",
      "Saved ._ukdrill_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukdrill_comments.csv\n",
      "Processing file: UKfood_comments.csv\n",
      "Saved UKfood_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKfood_comments.csv\n",
      "Processing file: ._UKfood_comments.csv\n",
      "Saved ._UKfood_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKfood_comments.csv\n",
      "Processing file: UKGardening_comments.csv\n",
      "Saved UKGardening_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKGardening_comments.csv\n",
      "Processing file: ._UKGardening_comments.csv\n",
      "Saved ._UKGardening_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKGardening_comments.csv\n",
      "Processing file: UKhiking_comments.csv\n",
      "Saved UKhiking_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKhiking_comments.csv\n",
      "Processing file: ._UKhiking_comments.csv\n",
      "Saved ._UKhiking_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKhiking_comments.csv\n",
      "Processing file: ukhiphopheads_comments.csv\n",
      "Saved ukhiphopheads_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukhiphopheads_comments.csv\n",
      "Processing file: ._ukhiphopheads_comments.csv\n",
      "Saved ._ukhiphopheads_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukhiphopheads_comments.csv\n",
      "Processing file: ukmedicalcannabis_comments.csv\n",
      "Saved ukmedicalcannabis_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukmedicalcannabis_comments.csv\n",
      "Processing file: ._ukmedicalcannabis_comments.csv\n",
      "Saved ._ukmedicalcannabis_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukmedicalcannabis_comments.csv\n",
      "Processing file: uktrees_comments.csv\n",
      "Saved uktrees_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/uktrees_comments.csv\n",
      "Processing file: ._uktrees_comments.csv\n",
      "Saved ._uktrees_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uktrees_comments.csv\n",
      "Processing file: uktrucking_comments.csv\n",
      "Saved uktrucking_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/uktrucking_comments.csv\n",
      "Processing file: ._uktrucking_comments.csv\n",
      "Saved ._uktrucking_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uktrucking_comments.csv\n",
      "Processing file: VapingUK_comments.csv\n",
      "Saved VapingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/VapingUK_comments.csv\n",
      "Processing file: ._VapingUK_comments.csv\n",
      "Saved ._VapingUK_comments.csv to /Volumes/Untitled/reddit/immigration_subreddits/._VapingUK_comments.csv\n",
      "Processing file: 90DayFianceUK_submissions.csv\n",
      "Saved 90DayFianceUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/90DayFianceUK_submissions.csv\n",
      "Processing file: ._90DayFianceUK_submissions.csv\n",
      "Saved ._90DayFianceUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._90DayFianceUK_submissions.csv\n",
      "Processing file: BitcoinUK_submissions.csv\n",
      "Saved BitcoinUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BitcoinUK_submissions.csv\n",
      "Processing file: ._BitcoinUK_submissions.csv\n",
      "Saved ._BitcoinUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BitcoinUK_submissions.csv\n",
      "Processing file: ActuaryUK_submissions.csv\n",
      "Saved ActuaryUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ActuaryUK_submissions.csv\n",
      "Processing file: ._ActuaryUK_submissions.csv\n",
      "Saved ._ActuaryUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ActuaryUK_submissions.csv\n",
      "Processing file: uknews_submissions.csv\n",
      "Saved uknews_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uknews_submissions.csv\n",
      "Processing file: ._uknews_submissions.csv\n",
      "Saved ._uknews_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uknews_submissions.csv\n",
      "Processing file: ADHDUK_submissions.csv\n",
      "Saved ADHDUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ADHDUK_submissions.csv\n",
      "Processing file: ._ADHDUK_submissions.csv\n",
      "Saved ._ADHDUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ADHDUK_submissions.csv\n",
      "Processing file: london_submissions.csv\n",
      "Saved london_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/london_submissions.csv\n",
      "Processing file: ._london_submissions.csv\n",
      "Saved ._london_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._london_submissions.csv\n",
      "Processing file: tories_submissions.csv\n",
      "Saved tories_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/tories_submissions.csv\n",
      "Processing file: ._tories_submissions.csv\n",
      "Saved ._tories_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._tories_submissions.csv\n",
      "Processing file: ukeducation_submissions.csv\n",
      "Saved ukeducation_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukeducation_submissions.csv\n",
      "Processing file: ._ukeducation_submissions.csv\n",
      "Saved ._ukeducation_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukeducation_submissions.csv\n",
      "Processing file: uklandlords_submissions.csv\n",
      "Saved uklandlords_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uklandlords_submissions.csv\n",
      "Processing file: ._uklandlords_submissions.csv\n",
      "Saved ._uklandlords_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uklandlords_submissions.csv\n",
      "Processing file: ukvisa_submissions.csv\n",
      "Saved ukvisa_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukvisa_submissions.csv\n",
      "Processing file: ._ukvisa_submissions.csv\n",
      "Saved ._ukvisa_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukvisa_submissions.csv\n",
      "Processing file: brexit_submissions.csv\n",
      "Saved brexit_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/brexit_submissions.csv\n",
      "Processing file: ._brexit_submissions.csv\n",
      "Saved ._brexit_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._brexit_submissions.csv\n",
      "Processing file: LabourPartyUK_submissions.csv\n",
      "Saved LabourPartyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/LabourPartyUK_submissions.csv\n",
      "Processing file: ._LabourPartyUK_submissions.csv\n",
      "Saved ._LabourPartyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._LabourPartyUK_submissions.csv\n",
      "Processing file: LabourUK_submissions.csv\n",
      "Saved LabourUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/LabourUK_submissions.csv\n",
      "Processing file: ._LabourUK_submissions.csv\n",
      "Saved ._LabourUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._LabourUK_submissions.csv\n",
      "Processing file: UKJobs_submissions.csv\n",
      "Saved UKJobs_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKJobs_submissions.csv\n",
      "Processing file: ._UKJobs_submissions.csv\n",
      "Saved ._UKJobs_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKJobs_submissions.csv\n",
      "Processing file: BrexitMemes_submissions.csv\n",
      "Saved BrexitMemes_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BrexitMemes_submissions.csv\n",
      "Processing file: ._BrexitMemes_submissions.csv\n",
      "Saved ._BrexitMemes_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BrexitMemes_submissions.csv\n",
      "Processing file: AskUK_submissions.csv\n",
      "Saved AskUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/AskUK_submissions.csv\n",
      "Processing file: ._AskUK_submissions.csv\n",
      "Saved ._AskUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._AskUK_submissions.csv\n",
      "Processing file: JuniorDoctorsUK_submissions.csv\n",
      "Saved JuniorDoctorsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/JuniorDoctorsUK_submissions.csv\n",
      "Processing file: ._JuniorDoctorsUK_submissions.csv\n",
      "Saved ._JuniorDoctorsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._JuniorDoctorsUK_submissions.csv\n",
      "Processing file: LegalAdviceUK_submissions.csv\n",
      "Saved LegalAdviceUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/LegalAdviceUK_submissions.csv\n",
      "Processing file: ._LegalAdviceUK_submissions.csv\n",
      "Saved ._LegalAdviceUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._LegalAdviceUK_submissions.csv\n",
      "Processing file: HousingUK_submissions.csv\n",
      "Saved HousingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/HousingUK_submissions.csv\n",
      "Processing file: ._HousingUK_submissions.csv\n",
      "Saved ._HousingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._HousingUK_submissions.csv\n",
      "Processing file: BritishMemes_submissions.csv\n",
      "Saved BritishMemes_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BritishMemes_submissions.csv\n",
      "Processing file: ._BritishMemes_submissions.csv\n",
      "Saved ._BritishMemes_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BritishMemes_submissions.csv\n",
      "Processing file: AmazonFlexUK_submissions.csv\n",
      "Saved AmazonFlexUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/AmazonFlexUK_submissions.csv\n",
      "Processing file: ._AmazonFlexUK_submissions.csv\n",
      "Saved ._AmazonFlexUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._AmazonFlexUK_submissions.csv\n",
      "Processing file: BenefitsAdviceUK_submissions.csv\n",
      "Saved BenefitsAdviceUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BenefitsAdviceUK_submissions.csv\n",
      "Processing file: ._BenefitsAdviceUK_submissions.csv\n",
      "Saved ._BenefitsAdviceUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BenefitsAdviceUK_submissions.csv\n",
      "Processing file: UKweddings_submissions.csv\n",
      "Saved UKweddings_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKweddings_submissions.csv\n",
      "Processing file: ._UKweddings_submissions.csv\n",
      "Saved ._UKweddings_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKweddings_submissions.csv\n",
      "Processing file: UKweedscene_submissions.csv\n",
      "Saved UKweedscene_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKweedscene_submissions.csv\n",
      "Processing file: ._UKweedscene_submissions.csv\n",
      "Saved ._UKweedscene_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKweedscene_submissions.csv\n",
      "Processing file: uklaw_submissions.csv\n",
      "Saved uklaw_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uklaw_submissions.csv\n",
      "Processing file: ._uklaw_submissions.csv\n",
      "Saved ._uklaw_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uklaw_submissions.csv\n",
      "Processing file: uklean_submissions.csv\n",
      "Saved uklean_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uklean_submissions.csv\n",
      "Processing file: ._uklean_submissions.csv\n",
      "Saved ._uklean_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uklean_submissions.csv\n",
      "Processing file: uktravel_submissions.csv\n",
      "Saved uktravel_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uktravel_submissions.csv\n",
      "Processing file: ._uktravel_submissions.csv\n",
      "Saved ._uktravel_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uktravel_submissions.csv\n",
      "Processing file: ukplace_submissions.csv\n",
      "Saved ukplace_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukplace_submissions.csv\n",
      "Processing file: ._ukplace_submissions.csv\n",
      "Saved ._ukplace_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukplace_submissions.csv\n",
      "Processing file: UKFrugal_submissions.csv\n",
      "Saved UKFrugal_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKFrugal_submissions.csv\n",
      "Processing file: ._UKFrugal_submissions.csv\n",
      "Saved ._UKFrugal_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKFrugal_submissions.csv\n",
      "Processing file: AmazonVineUK_submissions.csv\n",
      "Saved AmazonVineUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/AmazonVineUK_submissions.csv\n",
      "Processing file: ._AmazonVineUK_submissions.csv\n",
      "Saved ._AmazonVineUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._AmazonVineUK_submissions.csv\n",
      "Processing file: CurrentEventsUK_submissions.csv\n",
      "Saved CurrentEventsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/CurrentEventsUK_submissions.csv\n",
      "Processing file: ._CurrentEventsUK_submissions.csv\n",
      "Saved ._CurrentEventsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CurrentEventsUK_submissions.csv\n",
      "Processing file: BritishPolitics_submissions.csv\n",
      "Saved BritishPolitics_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BritishPolitics_submissions.csv\n",
      "Processing file: ._BritishPolitics_submissions.csv\n",
      "Saved ._BritishPolitics_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BritishPolitics_submissions.csv\n",
      "Processing file: AmericanExpatsUK_submissions.csv\n",
      "Saved AmericanExpatsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/AmericanExpatsUK_submissions.csv\n",
      "Processing file: ._AmericanExpatsUK_submissions.csv\n",
      "Saved ._AmericanExpatsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._AmericanExpatsUK_submissions.csv\n",
      "Processing file: ukipparty_submissions.csv\n",
      "Saved ukipparty_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukipparty_submissions.csv\n",
      "Processing file: ._ukipparty_submissions.csv\n",
      "Saved ._ukipparty_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukipparty_submissions.csv\n",
      "Processing file: uktrains_submissions.csv\n",
      "Saved uktrains_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uktrains_submissions.csv\n",
      "Processing file: ._uktrains_submissions.csv\n",
      "Saved ._uktrains_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uktrains_submissions.csv\n",
      "Processing file: ukmods_submissions.csv\n",
      "Saved ukmods_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukmods_submissions.csv\n",
      "Processing file: ._ukmods_submissions.csv\n",
      "Saved ._ukmods_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukmods_submissions.csv\n",
      "Processing file: TeachingUK_submissions.csv\n",
      "Saved TeachingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/TeachingUK_submissions.csv\n",
      "Processing file: ._TeachingUK_submissions.csv\n",
      "Saved ._TeachingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._TeachingUK_submissions.csv\n",
      "Processing file: british_submissions.csv\n",
      "Saved british_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/british_submissions.csv\n",
      "Processing file: ._british_submissions.csv\n",
      "Saved ._british_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._british_submissions.csv\n",
      "Processing file: UKPersonalFinance_submissions.csv\n",
      "Saved UKPersonalFinance_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKPersonalFinance_submissions.csv\n",
      "Processing file: ._UKPersonalFinance_submissions.csv\n",
      "Saved ._UKPersonalFinance_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKPersonalFinance_submissions.csv\n",
      "Processing file: leicester_submissions.csv\n",
      "Saved leicester_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/leicester_submissions.csv\n",
      "Processing file: ._leicester_submissions.csv\n",
      "Saved ._leicester_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._leicester_submissions.csv\n",
      "Processing file: GreatBritishmemes_submissions.csv\n",
      "Saved GreatBritishmemes_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/GreatBritishmemes_submissions.csv\n",
      "Processing file: ._GreatBritishmemes_submissions.csv\n",
      "Saved ._GreatBritishmemes_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._GreatBritishmemes_submissions.csv\n",
      "Processing file: UniUK_submissions.csv\n",
      "Saved UniUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UniUK_submissions.csv\n",
      "Processing file: ._UniUK_submissions.csv\n",
      "Saved ._UniUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UniUK_submissions.csv\n",
      "Processing file: UKInvesting_submissions.csv\n",
      "Saved UKInvesting_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKInvesting_submissions.csv\n",
      "Processing file: ._UKInvesting_submissions.csv\n",
      "Saved ._UKInvesting_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKInvesting_submissions.csv\n",
      "Processing file: medicalschooluk_submissions.csv\n",
      "Saved medicalschooluk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/medicalschooluk_submissions.csv\n",
      "Processing file: ._medicalschooluk_submissions.csv\n",
      "Saved ._medicalschooluk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._medicalschooluk_submissions.csv\n",
      "Processing file: ukguns_submissions.csv\n",
      "Saved ukguns_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukguns_submissions.csv\n",
      "Processing file: ._ukguns_submissions.csv\n",
      "Saved ._ukguns_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukguns_submissions.csv\n",
      "Processing file: UKParenting_submissions.csv\n",
      "Saved UKParenting_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKParenting_submissions.csv\n",
      "Processing file: ._UKParenting_submissions.csv\n",
      "Saved ._UKParenting_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKParenting_submissions.csv\n",
      "Processing file: apprenticeuk_submissions.csv\n",
      "Saved apprenticeuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/apprenticeuk_submissions.csv\n",
      "Processing file: ._apprenticeuk_submissions.csv\n",
      "Saved ._apprenticeuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._apprenticeuk_submissions.csv\n",
      "Processing file: AskABrit_submissions.csv\n",
      "Saved AskABrit_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/AskABrit_submissions.csv\n",
      "Processing file: ._AskABrit_submissions.csv\n",
      "Saved ._AskABrit_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._AskABrit_submissions.csv\n",
      "Processing file: baduk_submissions.csv\n",
      "Saved baduk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/baduk_submissions.csv\n",
      "Processing file: ._baduk_submissions.csv\n",
      "Saved ._baduk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._baduk_submissions.csv\n",
      "Processing file: bbuk_submissions.csv\n",
      "Saved bbuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/bbuk_submissions.csv\n",
      "Processing file: ._bbuk_submissions.csv\n",
      "Saved ._bbuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._bbuk_submissions.csv\n",
      "Processing file: beermoneyuk_submissions.csv\n",
      "Saved beermoneyuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/beermoneyuk_submissions.csv\n",
      "Processing file: ._beermoneyuk_submissions.csv\n",
      "Saved ._beermoneyuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._beermoneyuk_submissions.csv\n",
      "Processing file: BeyondTheBumpUK_submissions.csv\n",
      "Saved BeyondTheBumpUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BeyondTheBumpUK_submissions.csv\n",
      "Processing file: ._BeyondTheBumpUK_submissions.csv\n",
      "Saved ._BeyondTheBumpUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BeyondTheBumpUK_submissions.csv\n",
      "Processing file: bigbrotheruk_submissions.csv\n",
      "Saved bigbrotheruk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/bigbrotheruk_submissions.csv\n",
      "Processing file: ._bigbrotheruk_submissions.csv\n",
      "Saved ._bigbrotheruk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._bigbrotheruk_submissions.csv\n",
      "Processing file: BirminghamUK_submissions.csv\n",
      "Saved BirminghamUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BirminghamUK_submissions.csv\n",
      "Processing file: ._BirminghamUK_submissions.csv\n",
      "Saved ._BirminghamUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BirminghamUK_submissions.csv\n",
      "Processing file: Britain_submissions.csv\n",
      "Saved Britain_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/Britain_submissions.csv\n",
      "Processing file: ._Britain_submissions.csv\n",
      "Saved ._Britain_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Britain_submissions.csv\n",
      "Processing file: britisharmy_submissions.csv\n",
      "Saved britisharmy_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/britisharmy_submissions.csv\n",
      "Processing file: ._britisharmy_submissions.csv\n",
      "Saved ._britisharmy_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britisharmy_submissions.csv\n",
      "Processing file: britishmilitary_submissions.csv\n",
      "Saved britishmilitary_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/britishmilitary_submissions.csv\n",
      "Processing file: ._britishmilitary_submissions.csv\n",
      "Saved ._britishmilitary_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britishmilitary_submissions.csv\n",
      "Processing file: britishproblems_submissions.csv\n",
      "Saved britishproblems_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/britishproblems_submissions.csv\n",
      "Processing file: ._britishproblems_submissions.csv\n",
      "Saved ._britishproblems_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britishproblems_submissions.csv\n",
      "Processing file: BritishSuccess_submissions.csv\n",
      "Saved BritishSuccess_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BritishSuccess_submissions.csv\n",
      "Processing file: ._BritishSuccess_submissions.csv\n",
      "Saved ._BritishSuccess_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BritishSuccess_submissions.csv\n",
      "Processing file: BritishTV_submissions.csv\n",
      "Saved BritishTV_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/BritishTV_submissions.csv\n",
      "Processing file: ._BritishTV_submissions.csv\n",
      "Saved ._BritishTV_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._BritishTV_submissions.csv\n",
      "Processing file: britpics_submissions.csv\n",
      "Saved britpics_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/britpics_submissions.csv\n",
      "Processing file: ._britpics_submissions.csv\n",
      "Saved ._britpics_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britpics_submissions.csv\n",
      "Processing file: britposting_submissions.csv\n",
      "Saved britposting_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/britposting_submissions.csv\n",
      "Processing file: ._britposting_submissions.csv\n",
      "Saved ._britposting_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._britposting_submissions.csv\n",
      "Processing file: buildapcsalesuk_submissions.csv\n",
      "Saved buildapcsalesuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/buildapcsalesuk_submissions.csv\n",
      "Processing file: ._buildapcsalesuk_submissions.csv\n",
      "Saved ._buildapcsalesuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._buildapcsalesuk_submissions.csv\n",
      "Processing file: CANZUK_submissions.csv\n",
      "Saved CANZUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/CANZUK_submissions.csv\n",
      "Processing file: ._CANZUK_submissions.csv\n",
      "Saved ._CANZUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CANZUK_submissions.csv\n",
      "Processing file: CarTalkUK_submissions.csv\n",
      "Saved CarTalkUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/CarTalkUK_submissions.csv\n",
      "Processing file: ._CarTalkUK_submissions.csv\n",
      "Saved ._CarTalkUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CarTalkUK_submissions.csv\n",
      "Processing file: CasualUK_submissions.csv\n",
      "Saved CasualUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/CasualUK_submissions.csv\n",
      "Processing file: ._CasualUK_submissions.csv\n",
      "Saved ._CasualUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CasualUK_submissions.csv\n",
      "Processing file: CBDFlowerUK_submissions.csv\n",
      "Saved CBDFlowerUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/CBDFlowerUK_submissions.csv\n",
      "Processing file: ._CBDFlowerUK_submissions.csv\n",
      "Saved ._CBDFlowerUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CBDFlowerUK_submissions.csv\n",
      "Processing file: ChatSwapMeetDevonUK_submissions.csv\n",
      "Saved ChatSwapMeetDevonUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ChatSwapMeetDevonUK_submissions.csv\n",
      "Processing file: ._ChatSwapMeetDevonUK_submissions.csv\n",
      "Saved ._ChatSwapMeetDevonUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ChatSwapMeetDevonUK_submissions.csv\n",
      "Processing file: ContractorUK_submissions.csv\n",
      "Saved ContractorUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ContractorUK_submissions.csv\n",
      "Processing file: ._ContractorUK_submissions.csv\n",
      "Saved ._ContractorUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ContractorUK_submissions.csv\n",
      "Processing file: CoronavirusUK_submissions.csv\n",
      "Saved CoronavirusUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/CoronavirusUK_submissions.csv\n",
      "Processing file: ._CoronavirusUK_submissions.csv\n",
      "Saved ._CoronavirusUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CoronavirusUK_submissions.csv\n",
      "Processing file: CurlyHairUK_submissions.csv\n",
      "Saved CurlyHairUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/CurlyHairUK_submissions.csv\n",
      "Processing file: ._CurlyHairUK_submissions.csv\n",
      "Saved ._CurlyHairUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._CurlyHairUK_submissions.csv\n",
      "Processing file: DIYUK_submissions.csv\n",
      "Saved DIYUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/DIYUK_submissions.csv\n",
      "Processing file: ._DIYUK_submissions.csv\n",
      "Saved ._DIYUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._DIYUK_submissions.csv\n",
      "Processing file: doctorsUK_submissions.csv\n",
      "Saved doctorsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/doctorsUK_submissions.csv\n",
      "Processing file: ._doctorsUK_submissions.csv\n",
      "Saved ._doctorsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._doctorsUK_submissions.csv\n",
      "Processing file: drivingUK_submissions.csv\n",
      "Saved drivingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/drivingUK_submissions.csv\n",
      "Processing file: ._drivingUK_submissions.csv\n",
      "Saved ._drivingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._drivingUK_submissions.csv\n",
      "Processing file: FIREUK_submissions.csv\n",
      "Saved FIREUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/FIREUK_submissions.csv\n",
      "Processing file: ._FIREUK_submissions.csv\n",
      "Saved ._FIREUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._FIREUK_submissions.csv\n",
      "Processing file: foraginguk_submissions.csv\n",
      "Saved foraginguk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/foraginguk_submissions.csv\n",
      "Processing file: ._foraginguk_submissions.csv\n",
      "Saved ._foraginguk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._foraginguk_submissions.csv\n",
      "Processing file: GardeningUK_submissions.csv\n",
      "Saved GardeningUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/GardeningUK_submissions.csv\n",
      "Processing file: ._GardeningUK_submissions.csv\n",
      "Saved ._GardeningUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._GardeningUK_submissions.csv\n",
      "Processing file: Gayuklads_submissions.csv\n",
      "Saved Gayuklads_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/Gayuklads_submissions.csv\n",
      "Processing file: ._Gayuklads_submissions.csv\n",
      "Saved ._Gayuklads_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Gayuklads_submissions.csv\n",
      "Processing file: Gayuksnapchat_submissions.csv\n",
      "Saved Gayuksnapchat_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/Gayuksnapchat_submissions.csv\n",
      "Processing file: ._Gayuksnapchat_submissions.csv\n",
      "Saved ._Gayuksnapchat_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Gayuksnapchat_submissions.csv\n",
      "Processing file: hanguk_submissions.csv\n",
      "Saved hanguk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/hanguk_submissions.csv\n",
      "Processing file: ._hanguk_submissions.csv\n",
      "Saved ._hanguk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._hanguk_submissions.csv\n",
      "Processing file: heyUK_submissions.csv\n",
      "Saved heyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/heyUK_submissions.csv\n",
      "Processing file: ._heyUK_submissions.csv\n",
      "Saved ._heyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._heyUK_submissions.csv\n",
      "Processing file: HorseRacingUK_submissions.csv\n",
      "Saved HorseRacingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/HorseRacingUK_submissions.csv\n",
      "Processing file: ._HorseRacingUK_submissions.csv\n",
      "Saved ._HorseRacingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._HorseRacingUK_submissions.csv\n",
      "Processing file: HouseplantsUK_submissions.csv\n",
      "Saved HouseplantsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/HouseplantsUK_submissions.csv\n",
      "Processing file: ._HouseplantsUK_submissions.csv\n",
      "Saved ._HouseplantsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._HouseplantsUK_submissions.csv\n",
      "Processing file: hwsukrep_submissions.csv\n",
      "Saved hwsukrep_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/hwsukrep_submissions.csv\n",
      "Processing file: ._hwsukrep_submissions.csv\n",
      "Saved ._hwsukrep_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._hwsukrep_submissions.csv\n",
      "Processing file: JustEatUK_submissions.csv\n",
      "Saved JustEatUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/JustEatUK_submissions.csv\n",
      "Processing file: ._JustEatUK_submissions.csv\n",
      "Saved ._JustEatUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._JustEatUK_submissions.csv\n",
      "Processing file: kentuk_submissions.csv\n",
      "Saved kentuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/kentuk_submissions.csv\n",
      "Processing file: ._kentuk_submissions.csv\n",
      "Saved ._kentuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._kentuk_submissions.csv\n",
      "Processing file: ketouk_submissions.csv\n",
      "Saved ketouk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ketouk_submissions.csv\n",
      "Processing file: ._ketouk_submissions.csv\n",
      "Saved ._ketouk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ketouk_submissions.csv\n",
      "Processing file: LearnerDriverUK_submissions.csv\n",
      "Saved LearnerDriverUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/LearnerDriverUK_submissions.csv\n",
      "Processing file: ._LearnerDriverUK_submissions.csv\n",
      "Saved ._LearnerDriverUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._LearnerDriverUK_submissions.csv\n",
      "Processing file: MAFS_UK_submissions.csv\n",
      "Saved MAFS_UK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/MAFS_UK_submissions.csv\n",
      "Processing file: ._MAFS_UK_submissions.csv\n",
      "Saved ._MAFS_UK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MAFS_UK_submissions.csv\n",
      "Processing file: MagicMushroomsUK_submissions.csv\n",
      "Saved MagicMushroomsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/MagicMushroomsUK_submissions.csv\n",
      "Processing file: ._MagicMushroomsUK_submissions.csv\n",
      "Saved ._MagicMushroomsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MagicMushroomsUK_submissions.csv\n",
      "Processing file: MakeUpAddictionUK_submissions.csv\n",
      "Saved MakeUpAddictionUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/MakeUpAddictionUK_submissions.csv\n",
      "Processing file: ._MakeUpAddictionUK_submissions.csv\n",
      "Saved ._MakeUpAddictionUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MakeUpAddictionUK_submissions.csv\n",
      "Processing file: ManchesterUKmeets_submissions.csv\n",
      "Saved ManchesterUKmeets_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ManchesterUKmeets_submissions.csv\n",
      "Processing file: ._ManchesterUKmeets_submissions.csv\n",
      "Saved ._ManchesterUKmeets_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ManchesterUKmeets_submissions.csv\n",
      "Processing file: MarriedAtFirstSightUk_submissions.csv\n",
      "Saved MarriedAtFirstSightUk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/MarriedAtFirstSightUk_submissions.csv\n",
      "Processing file: ._MarriedAtFirstSightUk_submissions.csv\n",
      "Saved ._MarriedAtFirstSightUk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MarriedAtFirstSightUk_submissions.csv\n",
      "Processing file: MentalHealthUK_submissions.csv\n",
      "Saved MentalHealthUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/MentalHealthUK_submissions.csv\n",
      "Processing file: ._MentalHealthUK_submissions.csv\n",
      "Saved ._MentalHealthUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._MentalHealthUK_submissions.csv\n",
      "Processing file: Mortgageadviceuk_submissions.csv\n",
      "Saved Mortgageadviceuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/Mortgageadviceuk_submissions.csv\n",
      "Processing file: ._Mortgageadviceuk_submissions.csv\n",
      "Saved ._Mortgageadviceuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._Mortgageadviceuk_submissions.csv\n",
      "Processing file: NewsOfTheUK_submissions.csv\n",
      "Saved NewsOfTheUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/NewsOfTheUK_submissions.csv\n",
      "Processing file: ._NewsOfTheUK_submissions.csv\n",
      "Saved ._NewsOfTheUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._NewsOfTheUK_submissions.csv\n",
      "Processing file: NFLUK_submissions.csv\n",
      "Saved NFLUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/NFLUK_submissions.csv\n",
      "Processing file: ._NFLUK_submissions.csv\n",
      "Saved ._NFLUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._NFLUK_submissions.csv\n",
      "Processing file: NursingUK_submissions.csv\n",
      "Saved NursingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/NursingUK_submissions.csv\n",
      "Processing file: ._NursingUK_submissions.csv\n",
      "Saved ._NursingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._NursingUK_submissions.csv\n",
      "Processing file: OrnithologyUK_submissions.csv\n",
      "Saved OrnithologyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/OrnithologyUK_submissions.csv\n",
      "Processing file: ._OrnithologyUK_submissions.csv\n",
      "Saved ._OrnithologyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._OrnithologyUK_submissions.csv\n",
      "Processing file: policeuk_submissions.csv\n",
      "Saved policeuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/policeuk_submissions.csv\n",
      "Processing file: ._policeuk_submissions.csv\n",
      "Saved ._policeuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._policeuk_submissions.csv\n",
      "Processing file: PregnancyUK_submissions.csv\n",
      "Saved PregnancyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/PregnancyUK_submissions.csv\n",
      "Processing file: ._PregnancyUK_submissions.csv\n",
      "Saved ._PregnancyUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._PregnancyUK_submissions.csv\n",
      "Processing file: premeduk_submissions.csv\n",
      "Saved premeduk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/premeduk_submissions.csv\n",
      "Processing file: ._premeduk_submissions.csv\n",
      "Saved ._premeduk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._premeduk_submissions.csv\n",
      "Processing file: prsuk_submissions.csv\n",
      "Saved prsuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/prsuk_submissions.csv\n",
      "Processing file: ._prsuk_submissions.csv\n",
      "Saved ._prsuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._prsuk_submissions.csv\n",
      "Processing file: RPDR_UK_submissions.csv\n",
      "Saved RPDR_UK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/RPDR_UK_submissions.csv\n",
      "Processing file: ._RPDR_UK_submissions.csv\n",
      "Saved ._RPDR_UK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._RPDR_UK_submissions.csv\n",
      "Processing file: SkincareAddictionUK_submissions.csv\n",
      "Saved SkincareAddictionUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/SkincareAddictionUK_submissions.csv\n",
      "Processing file: ._SkincareAddictionUK_submissions.csv\n",
      "Saved ._SkincareAddictionUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._SkincareAddictionUK_submissions.csv\n",
      "Processing file: smallbusinessuk_submissions.csv\n",
      "Saved smallbusinessuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/smallbusinessuk_submissions.csv\n",
      "Processing file: ._smallbusinessuk_submissions.csv\n",
      "Saved ._smallbusinessuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._smallbusinessuk_submissions.csv\n",
      "Processing file: SteroidsUK_submissions.csv\n",
      "Saved SteroidsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/SteroidsUK_submissions.csv\n",
      "Processing file: ._SteroidsUK_submissions.csv\n",
      "Saved ._SteroidsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._SteroidsUK_submissions.csv\n",
      "Processing file: superstonkuk_submissions.csv\n",
      "Saved superstonkuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/superstonkuk_submissions.csv\n",
      "Processing file: ._superstonkuk_submissions.csv\n",
      "Saved ._superstonkuk_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._superstonkuk_submissions.csv\n",
      "Processing file: transgenderUK_submissions.csv\n",
      "Saved transgenderUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/transgenderUK_submissions.csv\n",
      "Processing file: ._transgenderUK_submissions.csv\n",
      "Saved ._transgenderUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._transgenderUK_submissions.csv\n",
      "Processing file: TrapsUK_submissions.csv\n",
      "Saved TrapsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/TrapsUK_submissions.csv\n",
      "Processing file: ._TrapsUK_submissions.csv\n",
      "Saved ._TrapsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._TrapsUK_submissions.csv\n",
      "Processing file: UbereatsUK_submissions.csv\n",
      "Saved UbereatsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UbereatsUK_submissions.csv\n",
      "Processing file: ._UbereatsUK_submissions.csv\n",
      "Saved ._UbereatsUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UbereatsUK_submissions.csv\n",
      "Processing file: UK_beer_submissions.csv\n",
      "Saved UK_beer_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UK_beer_submissions.csv\n",
      "Processing file: ._UK_beer_submissions.csv\n",
      "Saved ._UK_beer_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UK_beer_submissions.csv\n",
      "Processing file: UK_Food_submissions.csv\n",
      "Saved UK_Food_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UK_Food_submissions.csv\n",
      "Processing file: ._UK_Food_submissions.csv\n",
      "Saved ._UK_Food_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UK_Food_submissions.csv\n",
      "Processing file: UK_Pets_submissions.csv\n",
      "Saved UK_Pets_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UK_Pets_submissions.csv\n",
      "Processing file: ._UK_Pets_submissions.csv\n",
      "Saved ._UK_Pets_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UK_Pets_submissions.csv\n",
      "Processing file: UKbands_submissions.csv\n",
      "Saved UKbands_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKbands_submissions.csv\n",
      "Processing file: ._UKbands_submissions.csv\n",
      "Saved ._UKbands_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKbands_submissions.csv\n",
      "Processing file: UKBBQ_submissions.csv\n",
      "Saved UKBBQ_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKBBQ_submissions.csv\n",
      "Processing file: ._UKBBQ_submissions.csv\n",
      "Saved ._UKBBQ_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKBBQ_submissions.csv\n",
      "Processing file: ukbike_submissions.csv\n",
      "Saved ukbike_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukbike_submissions.csv\n",
      "Processing file: ._ukbike_submissions.csv\n",
      "Saved ._ukbike_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukbike_submissions.csv\n",
      "Processing file: UKbills_submissions.csv\n",
      "Saved UKbills_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKbills_submissions.csv\n",
      "Processing file: ._UKbills_submissions.csv\n",
      "Saved ._UKbills_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKbills_submissions.csv\n",
      "Processing file: ukcigars_submissions.csv\n",
      "Saved ukcigars_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukcigars_submissions.csv\n",
      "Processing file: ._ukcigars_submissions.csv\n",
      "Saved ._ukcigars_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukcigars_submissions.csv\n",
      "Processing file: UKcoins_submissions.csv\n",
      "Saved UKcoins_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKcoins_submissions.csv\n",
      "Processing file: ._UKcoins_submissions.csv\n",
      "Saved ._UKcoins_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKcoins_submissions.csv\n",
      "Processing file: UKDota_submissions.csv\n",
      "Saved UKDota_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKDota_submissions.csv\n",
      "Processing file: ._UKDota_submissions.csv\n",
      "Saved ._UKDota_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKDota_submissions.csv\n",
      "Processing file: ukdrill_submissions.csv\n",
      "Saved ukdrill_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukdrill_submissions.csv\n",
      "Processing file: ._ukdrill_submissions.csv\n",
      "Saved ._ukdrill_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukdrill_submissions.csv\n",
      "Processing file: UKfood_submissions.csv\n",
      "Saved UKfood_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKfood_submissions.csv\n",
      "Processing file: ._UKfood_submissions.csv\n",
      "Saved ._UKfood_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKfood_submissions.csv\n",
      "Processing file: UKGardening_submissions.csv\n",
      "Saved UKGardening_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKGardening_submissions.csv\n",
      "Processing file: ._UKGardening_submissions.csv\n",
      "Saved ._UKGardening_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKGardening_submissions.csv\n",
      "Processing file: UKhiking_submissions.csv\n",
      "Saved UKhiking_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/UKhiking_submissions.csv\n",
      "Processing file: ._UKhiking_submissions.csv\n",
      "Saved ._UKhiking_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._UKhiking_submissions.csv\n",
      "Processing file: ukhiphopheads_submissions.csv\n",
      "Saved ukhiphopheads_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukhiphopheads_submissions.csv\n",
      "Processing file: ._ukhiphopheads_submissions.csv\n",
      "Saved ._ukhiphopheads_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukhiphopheads_submissions.csv\n",
      "Processing file: ukmedicalcannabis_submissions.csv\n",
      "Saved ukmedicalcannabis_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukmedicalcannabis_submissions.csv\n",
      "Processing file: ._ukmedicalcannabis_submissions.csv\n",
      "Saved ._ukmedicalcannabis_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukmedicalcannabis_submissions.csv\n",
      "Processing file: ukpolitics_submissions.csv\n",
      "Saved ukpolitics_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/ukpolitics_submissions.csv\n",
      "Processing file: ._ukpolitics_submissions.csv\n",
      "Saved ._ukpolitics_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._ukpolitics_submissions.csv\n",
      "Processing file: uktrees_submissions.csv\n",
      "Saved uktrees_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uktrees_submissions.csv\n",
      "Processing file: ._uktrees_submissions.csv\n",
      "Saved ._uktrees_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uktrees_submissions.csv\n",
      "Processing file: uktrucking_submissions.csv\n",
      "Saved uktrucking_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/uktrucking_submissions.csv\n",
      "Processing file: ._uktrucking_submissions.csv\n",
      "Saved ._uktrucking_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._uktrucking_submissions.csv\n",
      "Processing file: VapingUK_submissions.csv\n",
      "Saved VapingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/VapingUK_submissions.csv\n",
      "Processing file: ._VapingUK_submissions.csv\n",
      "Saved ._VapingUK_submissions.csv to /Volumes/Untitled/reddit/immigration_subreddits/._VapingUK_submissions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\")\n",
    "\n",
    "input_path = r\"/Volumes/Untitled/reddit/cleaned_subreddits1\"\n",
    "output_path = r\"/Volumes/Untitled/reddit/immigration_subreddits\"\n",
    "\n",
    "# Define immigration-related keywords, including terms about \"stop the boat\" and people coming via boats\n",
    "immigration_keywords = (\n",
    "    r'\\bimmigrat\\w*\\b|'\n",
    "    r'\\bRwanda\\s(Bill|Policy)\\b|'\n",
    "    r'\\b(asylum|refugee|asylum-seeker|refugees|asylum-seekers)\\b|'\n",
    "    r'\\bvisa\\w*\\b|'\n",
    "    r'\\b(undocumented|illegal)\\simmigrant\\w*\\b|'\n",
    "    r'\\b(deportation|detain\\w*|detention)\\b|'\n",
    "    r'\\b(border\\scontrol|immigration\\spolicy|migration\\spolicy)\\b|'\n",
    "    r'\\bpoints-based\\ssystem\\b|'\n",
    "    r'\\b(skilled\\sworker\\svisa|student\\svisa)\\b|'\n",
    "    r'\\b(overstay\\w*|overstayer\\w*)\\b|'\n",
    "    r'\\b(work\\svisa|family\\svisa|spouse\\svisa)\\b|'\n",
    "    r'\\b(settlement|permanent\\sresidence|PR\\sstatus)\\b|'\n",
    "    r'\\b(hostile\\senvironment)\\b|'\n",
    "    r'\\b(integration|assimilation|multiculturalism)\\b|'\n",
    "    r'\\b(naturalization|citizenship)\\b|'\n",
    "    r'\\b(migrant\\w*|expat\\w*)\\b|'\n",
    "    r'\\b(foreigner\\w*|foreign\\sworker\\w*)\\b|'\n",
    "    r'\\b(home\\soffice)\\b|'\n",
    "    r'\\b(Windrush)\\b|'\n",
    "    r'\\b(human\\srights|amnesty|appeal)\\b|'\n",
    "    r'\\b(brexit\\simmigration)\\b|'\n",
    "    r'\\b(Ukraine\\srefugee\\w*|Syrian\\srefugee\\w*|Afghan\\srefugee\\w*|Palestinian\\srefugee\\w*|Iranian\\srefugee\\w*|Sudanese\\srefugee\\w*)\\b|'\n",
    "    r'\\b(immigration\\scourt|tribunal)\\b|'\n",
    "    r'\\b(sponsor\\w*\\svisa)\\b|'\n",
    "    r'\\b(protection\\sclaim)\\b|'\n",
    "    r'\\b(temporary\\sprotection|humanitarian\\sprotection)\\b|'\n",
    "    r'\\b(resettlement\\sscheme|community\\ssponsorship)\\b|'\n",
    "    r'\\b(legal\\simmigration|illegal\\simmigration)\\b|'\n",
    "    r'\\b(immigration\\scontrol)\\b|'\n",
    "    r'\\b(stop\\sthe\\sboats?)\\b|'\n",
    "    r'\\b(boat\\smigrants?)\\b|'\n",
    "    r'\\b(small\\sboats?)\\b|'\n",
    "    r'\\b(channel\\scrossings?)\\b|'\n",
    "    r'\\b(illegal\\sboat\\smigration)\\b|'\n",
    "    r'\\b(intercepting\\sboats?)\\b|'\n",
    "    r'\\b(migrant\\sboats?)\\b|'\n",
    "    r'\\b(people\\ssmugglers?)\\b'\n",
    ")\n",
    "\n",
    "\n",
    "for filename in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, filename)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path, encoding= 'utf-8', lineterminator='\\n')\n",
    "\n",
    "    if \"comments\" in filename:\n",
    "        column_names = ['score', 'date', 'is_submitter', 'user', 'link', 'body', 'is_comment', 'subreddit']\n",
    "    else:\n",
    "        # column names for submissions\n",
    "        column_names = ['score', 'date', 'title', 'num_comments', 'user', 'link', 'body', 'is_comment', 'subreddit']\n",
    "\n",
    "    # Set column names, reorder body to first column\n",
    "    df = df.reindex(columns=column_names)\n",
    "    df = df[['body'] + [col for col in df.columns if col != 'body']]\n",
    "\n",
    "    # Ensure 'body' is a string type (considering potential issues)\n",
    "    if not pd.api.types.is_string_dtype(df['body']):\n",
    "        try:\n",
    "            # Attempt conversion to string, handling potential errors\n",
    "            df['body'] = df['body'].astype(str)\n",
    "        except (ValueError, TypeError):  # Catch specific errors for robustness\n",
    "            # Handle non-convertible values (e.g., log a message or fill with NaNs)\n",
    "            print(f\"Warning: Encountered non-string values in 'body' column for {filename}.\")\n",
    "\n",
    "    # Filter based on immigration keywords\n",
    "    df_filtered = df[df['body'].str.contains(immigration_keywords, case=False, na=False)]\n",
    "\n",
    "    # Print the current file being processed\n",
    "    print(f\"Processing file: {filename}\")\n",
    "\n",
    "    # Save\n",
    "    output_file_path = os.path.join(output_path, filename)\n",
    "    df_filtered.to_csv(output_file_path, index=False)\n",
    "    print(f\"Saved {filename} to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d0c29e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied leicester_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._leicester_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukeducation_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukeducation_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied medicalschooluk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._medicalschooluk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied apprenticeuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._apprenticeuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied AskABrit_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._AskABrit_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied baduk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._baduk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied bbuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._bbuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied beermoneyuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._beermoneyuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BeyondTheBumpUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BeyondTheBumpUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied bigbrotheruk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._bigbrotheruk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BirminghamUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BirminghamUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Britain_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Britain_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britisharmy_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britisharmy_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britishmilitary_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britishmilitary_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britishproblems_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britishproblems_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BritishSuccess_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BritishSuccess_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BritishTV_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BritishTV_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britpics_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britpics_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britposting_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britposting_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied buildapcsalesuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._buildapcsalesuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CANZUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CANZUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CarTalkUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CarTalkUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CasualUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CasualUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CBDFlowerUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CBDFlowerUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ChatSwapMeetDevonUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ChatSwapMeetDevonUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ContractorUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ContractorUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CoronavirusUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CoronavirusUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CurlyHairUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CurlyHairUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied DIYUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._DIYUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied doctorsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._doctorsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied drivingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._drivingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied FIREUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._FIREUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied foraginguk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._foraginguk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied GardeningUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._GardeningUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Gayuklads_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Gayuklads_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Gayuksnapchat_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Gayuksnapchat_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied hanguk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._hanguk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied heyUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._heyUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied HorseRacingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._HorseRacingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied HouseplantsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._HouseplantsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied hwsukrep_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._hwsukrep_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied JustEatUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._JustEatUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied kentuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._kentuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ketouk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ketouk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied LearnerDriverUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._LearnerDriverUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MAFS_UK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MAFS_UK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MagicMushroomsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MagicMushroomsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MakeUpAddictionUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MakeUpAddictionUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ManchesterUKmeets_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ManchesterUKmeets_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MarriedAtFirstSightUk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MarriedAtFirstSightUk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MentalHealthUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MentalHealthUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Mortgageadviceuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Mortgageadviceuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied NewsOfTheUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._NewsOfTheUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied NFLUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._NFLUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied NursingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._NursingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied OrnithologyUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._OrnithologyUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied policeuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._policeuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied PregnancyUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._PregnancyUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied premeduk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._premeduk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied prsuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._prsuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied RPDR_UK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._RPDR_UK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied SkincareAddictionUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._SkincareAddictionUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied smallbusinessuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._smallbusinessuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied SteroidsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._SteroidsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied superstonkuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._superstonkuk_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied transgenderUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._transgenderUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied TrapsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._TrapsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UbereatsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UbereatsUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UK_beer_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UK_beer_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UK_Food_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UK_Food_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UK_Pets_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UK_Pets_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKbands_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKbands_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKBBQ_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKBBQ_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukbike_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukbike_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKbills_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKbills_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukcigars_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukcigars_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKcoins_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKcoins_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKDota_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKDota_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukdrill_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukdrill_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKfood_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKfood_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKGardening_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKGardening_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKhiking_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKhiking_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukhiphopheads_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukhiphopheads_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukmedicalcannabis_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukmedicalcannabis_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uktrees_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uktrees_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uktrucking_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uktrucking_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied VapingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._VapingUK_comments.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied 90DayFianceUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._90DayFianceUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BitcoinUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BitcoinUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ActuaryUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ActuaryUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uknews_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uknews_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ADHDUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ADHDUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied london_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._london_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied tories_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._tories_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukeducation_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukeducation_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uklandlords_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uklandlords_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukvisa_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukvisa_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied brexit_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._brexit_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied LabourPartyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._LabourPartyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied LabourUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._LabourUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKJobs_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKJobs_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BrexitMemes_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BrexitMemes_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied AskUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._AskUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied JuniorDoctorsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._JuniorDoctorsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied LegalAdviceUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._LegalAdviceUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied HousingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._HousingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BritishMemes_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BritishMemes_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied AmazonFlexUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._AmazonFlexUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BenefitsAdviceUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BenefitsAdviceUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKweddings_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKweddings_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKweedscene_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKweedscene_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uklaw_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uklaw_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uklean_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uklean_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uktravel_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uktravel_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukplace_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukplace_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKFrugal_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKFrugal_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied AmazonVineUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._AmazonVineUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CurrentEventsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CurrentEventsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BritishPolitics_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BritishPolitics_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied AmericanExpatsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._AmericanExpatsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukipparty_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukipparty_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uktrains_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uktrains_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukmods_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukmods_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied TeachingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._TeachingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied british_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._british_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKPersonalFinance_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKPersonalFinance_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied leicester_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._leicester_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied GreatBritishmemes_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._GreatBritishmemes_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UniUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UniUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKInvesting_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKInvesting_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied medicalschooluk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._medicalschooluk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukguns_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukguns_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKParenting_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKParenting_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied apprenticeuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._apprenticeuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied AskABrit_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._AskABrit_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied baduk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._baduk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied bbuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._bbuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied beermoneyuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._beermoneyuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BeyondTheBumpUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BeyondTheBumpUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied bigbrotheruk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._bigbrotheruk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BirminghamUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BirminghamUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Britain_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Britain_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britisharmy_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britisharmy_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britishmilitary_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britishmilitary_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britishproblems_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britishproblems_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BritishSuccess_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BritishSuccess_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied BritishTV_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._BritishTV_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britpics_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britpics_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied britposting_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._britposting_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied buildapcsalesuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._buildapcsalesuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CANZUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CANZUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CarTalkUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CarTalkUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CasualUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CasualUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CBDFlowerUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CBDFlowerUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ChatSwapMeetDevonUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ChatSwapMeetDevonUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ContractorUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ContractorUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CoronavirusUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CoronavirusUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied CurlyHairUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._CurlyHairUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied DIYUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._DIYUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied doctorsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._doctorsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied drivingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._drivingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied FIREUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._FIREUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied foraginguk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._foraginguk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied GardeningUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._GardeningUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Gayuklads_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Gayuklads_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Gayuksnapchat_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Gayuksnapchat_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied hanguk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._hanguk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied heyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._heyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied HorseRacingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._HorseRacingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied HouseplantsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._HouseplantsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied hwsukrep_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._hwsukrep_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied JustEatUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._JustEatUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied kentuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._kentuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ketouk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ketouk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied LearnerDriverUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._LearnerDriverUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MAFS_UK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MAFS_UK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MagicMushroomsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MagicMushroomsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MakeUpAddictionUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MakeUpAddictionUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ManchesterUKmeets_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ManchesterUKmeets_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MarriedAtFirstSightUk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MarriedAtFirstSightUk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied MentalHealthUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._MentalHealthUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied Mortgageadviceuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._Mortgageadviceuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied NewsOfTheUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._NewsOfTheUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied NFLUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._NFLUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied NursingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._NursingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied OrnithologyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._OrnithologyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied policeuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._policeuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied PregnancyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._PregnancyUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied premeduk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._premeduk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied prsuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._prsuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied RPDR_UK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._RPDR_UK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied SkincareAddictionUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._SkincareAddictionUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied smallbusinessuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._smallbusinessuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied SteroidsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._SteroidsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied superstonkuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._superstonkuk_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied transgenderUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._transgenderUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied TrapsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._TrapsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UbereatsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UbereatsUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UK_beer_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UK_beer_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UK_Food_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UK_Food_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UK_Pets_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UK_Pets_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKbands_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKbands_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKBBQ_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKBBQ_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukbike_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukbike_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKbills_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKbills_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukcigars_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukcigars_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKcoins_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKcoins_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKDota_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKDota_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukdrill_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukdrill_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKfood_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKfood_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKGardening_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKGardening_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied UKhiking_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._UKhiking_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukhiphopheads_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukhiphopheads_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukmedicalcannabis_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukmedicalcannabis_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ukpolitics_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._ukpolitics_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uktrees_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uktrees_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied uktrucking_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._uktrucking_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied VapingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n",
      "Copied ._VapingUK_submissions.csv to /Volumes/Untitled/reddit/cleaned_subreddits1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "input_path = r\"/Volumes/Untitled/reddit/cleaned_subreddits\"\n",
    "immigration_subreddits_path = r\"/Volumes/Untitled/reddit/immigration_subreddits\"\n",
    "output_path = r\"/Volumes/Untitled/reddit/cleaned_subreddits1\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename not in os.listdir(immigration_subreddits_path):\n",
    "        source_file_path = os.path.join(input_path, filename)\n",
    "        destination_file_path = os.path.join(output_path, filename)\n",
    "        \n",
    "        # Copy the file to the output directory\n",
    "        shutil.copy(source_file_path, destination_file_path)\n",
    "        print(f\"Copied {filename} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f620c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n",
      "/var/folders/r_/kzyzqy3d39ggsy_pf019hz6m0000gp/T/ipykernel_15648/417478226.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([merged_df, df])\n"
     ]
    }
   ],
   "source": [
    "## merge all files in immigration_subreddits folder\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_path = r\"/Volumes/Untitled/reddit/immigration_subreddits\"\n",
    "output_path = r\"/Volumes/Untitled/reddit\"\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the files in the input directory\n",
    "\n",
    "for filename in os.listdir(input_path):\n",
    "    file_path = os.path.join(input_path, filename)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path, encoding='utf-8', lineterminator='\\n')\n",
    "    \n",
    "    # Append the data to the merged DataFrame\n",
    "    merged_df = pd.concat([merged_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "208e5d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged data to a CSV file\n",
    "merged_df.to_csv(r\"/Volumes/Untitled/reddit/all_reddit.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f9059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
